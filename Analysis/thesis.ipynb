{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\newcommand{\\matr}[1]\\textbf{#1}\n",
       "\\newcommand{\\vect}[1]{\\vec{#1}}\n",
       "\\usepackage[table,xcdraw]{xcolor}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\newcommand{\\matr}[1]\\textbf{#1}\n",
    "\\newcommand{\\vect}[1]{\\vec{#1}}\n",
    "\\usepackage[table,xcdraw]{xcolor}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To my dear supervisors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPCD simulation of polymers in solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will serve as the documentation of our efforts and results for my Bachelor's Thesis. The goal of this thesis will be the study of short/long-chained polymers in a liquid thats flowing around obstacles. The liquid will be simulated with MPCD, or \"Multi Particle Collision Dynamics\".\n",
    "\n",
    "I chose the language C++ for its familiar object-oriented nature and its proven execution-time. Output of the simulation will mostly be analysed in Python, specifically with Jupyter Notebook for a blend of beautiful visualizations and convenience. For simplification, the situation will be studied in 2D. The situation we specifically discussed is shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Situation](Assets/MPCD_Situation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there other people I can contact for the programming/implementation details?\n",
    "\n",
    "How do I model the obstacles?, the walls? = the same? Many particles, large molecules? circles?\n",
    "\n",
    "How should I initialize the velocities? How large can they be without distorting the simulation?\n",
    "\n",
    "If particles drift too far out of bounds, should they be destroyed, and should then new ones be created to keep the number constant? In other words, should there be a particle source?\n",
    "\n",
    "On what order should $D >> d$ be (see above) 100:1? 10:1? 1000:1?\n",
    "\n",
    "_\"In addition to the conservation of momentum and mass, SRD also\n",
    "locally conserves energy, which enables simulations in the microcanonical ensemble.\"_ - Winkler (what does this mean exactly?)\n",
    "\n",
    "_\"It must, however, be emphasized that all local algorithms such as MPC,\n",
    "DPD, and LB model compressible fluids, so that it takes time for the hydrodynamic interactions to “propagate” over longer distances. As a consequence,\n",
    "these methods become quite inefficient in the Stokes limit, where the Reynolds\n",
    "number approaches zero. Algorithms which incorporate an Oseen tensor do\n",
    "not share this shortcoming.\"_ - Winkler (is this a problem?)\n",
    "\n",
    "Winkler says in his paper that momentum, mass and energy are conserved locally. What does this mean exactly? -- I think this means conservation on a cell level.\n",
    "\n",
    "_\"Except for conservation laws and symmetry requirements, there are relatively few constraints on the structure of mesoscale algorithms. However, the constitutive relations and the transport coefficients depend on the details of the algorithm, so that the temperature and density dependencies of the transport coefficients can be quite different from those of real gases or liquids. However, this is not a problem as long as the functional form of the resulting hydrodynamic equations is correct. The mapping to real systems is achieved by tuning the relevant characteristic numbers, such as the Reynolds and Peclet numbers [12, 13], to those of a given experiment.\"_ - Winkler\n",
    "\n",
    "How can I test if my simulation is right? See if some parameter can be tuned to one of an experiment? How should we go about this?\n",
    "\n",
    "What fluid do we simulate? What is the density? Any special properties?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiparticle collision dynamics (MPCD), also known as Stochastic Rotation Dynamics (SRD)[@winkl2009] is a technique originally introduced to study the dynamics of complex fluids such as polymers in solution. Besides MPCD, there exist other mesoscopic models that have been constructed for this purpose, such as Langevin, Direct Simulation Monte Carlo and lattice Boltzmann methods.[@malev1999] We only concern ourselves with the application of MPCD, it follows that any comparison between methods are out of the scope of this thesis.\n",
    "\n",
    "The MPCD technique models the fluid using particles, their positions and velocities are treated as continuous variables. The system is divided up into cells that have no restriction on the number of particles, each of the cells is part of a regular lattice. The dynamics is split into two parts: Particle streaming and multiparticle collision dynamics. Particle streaming is treated exactly for each particle in the system, while the collision step is approximated on a cell level. The multiparticle collision dynamics conserves mass, momentum and energy and leads to the correct hydrodynamical equations.[@malev1999] The streaming and collision step are described in more detail in (TODO: section numbering)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The MPCD algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The system we are modelling consists of $N$ particles with mass $m$, continuous position $\\vec{r_{i}}$ and velocity $\\vec{v_{i}}$, where $i \\in \\{1, 2, \\dots, N\\}$. One timestep $\\Delta t$ shall correspond to having calculated all the new particle positions and velocities in the streaming and collision steps, respectively. For each of the $N$ particles, the streaming and collision steps are applied, and this pattern is repeated until the wanted number of timesteps have elapsed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The streaming step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The streaming step is very straightforward. The particle positions are simply updated according to\n",
    "\n",
    "\\begin{equation}\n",
    "\\vect{r_{i}} \\rightarrow \\vect{r_{i}} + \\Delta t \\cdot \\vect{v_{i}}\\textrm{,}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\Delta t$ is a small time interval.[@winkl2009][@malev1999]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The collision step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collision step is somewhat more complicated. It involves the mean velocity of all particles in a particular cell, $\\vect{V_c}$, the velocity of the particle $i$, $\\vec{v_i}$, and a rotation matrix $\\matr{R}(\\alpha)$. The vector $\\vect{v_i}$ is rotated relative to the mean velocity $\\vect{V_c}$ of all particles in cell $c$, cell $c$ being the cell which particle $i$ belongs to. It is shown in [@malev1999] that the rule,\n",
    "\n",
    "\\begin{equation}\n",
    "\\vect{v_i} \\rightarrow \\vect{V_c} + \\matr{R}(\\alpha) [\\vect{v_i} - \\vect{V_c}] \\textrm{,}\n",
    "\\end{equation}\n",
    "\n",
    "conserves mass, momentum and energy under the molecular chaos assumption[@malev1999][@winkl2009, molecular chaos, p.7]. The rotation matrix $\\matr{R}(\\alpha)$ is a simple 2d rotation matrix\n",
    "\n",
    "\\begin{equation}\n",
    "R(\\alpha) = \n",
    "\\left[ \\begin{array}{rr}\n",
    "cos(\\alpha) & -sin(\\alpha) \\\\\n",
    "sin(\\alpha) & cos(\\alpha) \\\\\n",
    "\\end{array}\\right],\n",
    "\\end{equation}\n",
    "\n",
    "where $\\alpha$ is sampled randomly on a per-cell basis. Furthermore, for each particle in the cell $\\alpha$ flips its sign with probability $\\frac{1}{2}$.[@winkl2009, (p.6)]\n",
    "The mean velocity of a cell is defined as\n",
    "\n",
    "\\begin{equation}\n",
    "\\vect{V_c} = \\frac{1}{N_c} \\sum_{i=1}^{N_c} \\vect{v_i} \\textrm{,}\n",
    "\\end{equation}\n",
    "\n",
    "where $N_c$ is the number of particles in cell c.[@malev1999]\n",
    "\n",
    "The original MPCD algorithm was not Galilean invariant. The problem lay in the \"molecular chaos\" assumption, which means that particles involved in a collision have no memory of earlier encounters when colliding. This assumption is problematic when the mean free path \n",
    "\n",
    "\\begin{equation}\n",
    "\\lambda = \\Delta t \\sqrt{\\frac{k_{B}T}{m}}\n",
    "\\end{equation}\n",
    "\n",
    "is small compared to the cell size $a$, since the same particles collide with each other repeatedly and thus build up correlations. When $\\lambda \\gg a$ Ihle and Kroll have shown that the molecular chaos assumption holds and the simulated results deviate from experimental ones only negligibly.[@ihlekroll2001, p.2][@winkl2009]\n",
    "\n",
    "The solution to this problem is to shift all particles by the same random vector $s$ before the collision step. The components of $s$ are sampled randomly from a uniform distribution in the interval $[-\\frac{a}{2}, \\frac{a}{2}]$. After the collision, the particles are shifted back by the same amount.[@ihlekroll2001]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the MPCD Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Pseudo) Random Number Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the pillars of this thesis is the generation of random rotation angles for the rotation matrix needed in the collision step. This proved to be somewhat difficult. First, the standard algorithm of the C++ standard library was tried, but it didn't qualify because it performed poorly in comparison to the second and third algorithms tried, which are called \"Mersenne Twister\" and \"xoshiro256++\", respectively.[@wiki:mersennetwister][@cppreference:prng][@unimi:xoshiro]\n",
    "\n",
    "The Mersenne Twister was implemented using the C++ standard library. The xoshiro256++ was implemented using Sebastian Vigna's code with some additions.[@unimi:xoshiro]\n",
    "\n",
    "To compare algorithms, and also to make sure that the implementation of the xoshiro256++ is right, a $\\chi^2$ test for discrete observations was used. The generated angles in the interval $[0, 2\\pi)$ were split into $k+1$ buckets, where $k$ is the number of degrees of freedom of the $\\chi^2$ distribution. The test error\n",
    "\n",
    "\\begin{equation}\n",
    "T = \\sum_{b=1}^{k+1}{\\frac{(N_o - E[N_b])^2}{E[N_b]}},\n",
    "\\end{equation}\n",
    "\n",
    "where $E[N_b] = \\frac{N}{b}, b \\in \\{1, 2, \\dots , k+1\\}$ is the expected bucket size, is compared to $\\chi^2_{1-\\alpha, k}$, where $\\alpha$ is the signifigance level. The null hypothesis\n",
    "\n",
    "$$\n",
    "H_0: \\textrm{The angles are distributed uniformly in the interval } [0, 2 \\pi)\n",
    "$$\n",
    "\n",
    "is tested against the alternative hypothesis\n",
    "\n",
    "$$\n",
    "H_1: \\textrm{The angles are not distributed uniformly in the interval } [0, 2 \\pi) \\textrm{.}\n",
    "$$\n",
    "\n",
    "If the test should have significance level $\\alpha$, $H_0$ is rejected if $T \\ge \\chi^2_{1-\\alpha, k}$.[@fruehwirthstat][@wiki:chisquaredtest][@wiki:goodnessoffit]\n",
    "\n",
    "The results of the $\\chi^2$ test are summarised in [TODO: Table, and table formatting]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../x64/Debug/Data/RNG/\"\n",
    "mersenne = \"mersenne_twister_chi2.csv\"\n",
    "xoshiro = \"xoshiro_chi2.csv\"\n",
    "index = [\"k\", \"chi^2 probability\"]\n",
    "out_path = \"Generated/\"\n",
    "new_name = \"chi2_results_dirty.csv\"\n",
    "mersenne_twister_chi2 = pd.read_csv(path + mersenne).set_index(index)\n",
    "xoshiro256plusplus_chi2 = pd.read_csv(path + xoshiro).set_index(index)\n",
    "results = mersenne_twister_chi2.join(xoshiro256plusplus_chi2, on = index, how = \"inner\")\n",
    "results_csv = results.to_csv(out_path + new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{table}[]\n",
       "\\begin{tabular}{llll}\n",
       "\\rowcolor[HTML]{4472C4} \n",
       "{\\color[HTML]{FFF} \\textbf{k}} & {\\color[HTML]{FFF} \\textbf{chi\\textasciicircum{}2   probability}} & {\\color[HTML]{FFF} \\textbf{observed   MT}} & {\\color[HTML]{FFF} \\textbf{observed XS256++}} \\\\\n",
       "\\rowcolor[HTML]{D9E1F2} \n",
       "1                              & 5.991                                                             & 0.292                                      & 0.068                                         \\\\\n",
       "2                              & 7.815                                                             & 1.626                                      & 3.682                                         \\\\\n",
       "\\rowcolor[HTML]{D9E1F2} \n",
       "3                              & 9.488                                                             & 3.735                                      & 2.124                                         \\\\\n",
       "4                              & 11.07                                                             & 4.255                                      & 4.525                                         \\\\\n",
       "\\rowcolor[HTML]{D9E1F2} \n",
       "5                              & 12.592                                                            & 2.86                                       & 6.345                                         \\\\\n",
       "6                              & 14.067                                                            & 4.071                                      & 6.377                                         \\\\\n",
       "\\rowcolor[HTML]{D9E1F2} \n",
       "7                              & 15.507                                                            & 8.662                                      & 11.731                                        \\\\\n",
       "8                              & 16.919                                                            & 14.426                                     & 8.693                                         \\\\\n",
       "\\rowcolor[HTML]{D9E1F2} \n",
       "9                              & 18.307                                                            & 11.732                                     & 6.932                                         \\\\\n",
       "10                             & 19.675                                                            & 9.857                                      & 5.939                                         \\\\\n",
       "\\rowcolor[HTML]{D9E1F2} \n",
       "11                             & 21.026                                                            & 10.438                                     & 11.73                                         \\\\\n",
       "12                             & 22.362                                                            & 10.985                                     & 15.543                                        \\\\\n",
       "\\rowcolor[HTML]{D9E1F2} \n",
       "13                             & 23.685                                                            & 22.603                                     & 12.022                                        \\\\\n",
       "14                             & 24.996                                                            & 13.988                                     & 12.923                                        \\\\\n",
       "\\rowcolor[HTML]{D9E1F2} \n",
       "15                             & 26.296                                                            & 15.526                                     & 20.71                                         \\\\\n",
       "16                             & 27.587                                                            & 16.288                                     & 11.501                                        \\\\\n",
       "\\rowcolor[HTML]{D9E1F2} \n",
       "17                             & 28.869                                                            & \\cellcolor[HTML]{F8CBAD}32.26              & 12.478                                        \\\\\n",
       "18                             & 30.144                                                            & \\cellcolor[HTML]{F8CBAD}31.787             & 13.882                                       \n",
       "\\end{tabular}\n",
       "\\end{table}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{table}[]\n",
    "\\begin{tabular}{llll}\n",
    "\\rowcolor[HTML]{4472C4} \n",
    "{\\color[HTML]{FFF} \\textbf{k}} & {\\color[HTML]{FFF} \\textbf{chi\\textasciicircum{}2   probability}} & {\\color[HTML]{FFF} \\textbf{observed   MT}} & {\\color[HTML]{FFF} \\textbf{observed XS256++}} \\\\\n",
    "\\rowcolor[HTML]{D9E1F2} \n",
    "1                              & 5.991                                                             & 0.292                                      & 0.068                                         \\\\\n",
    "2                              & 7.815                                                             & 1.626                                      & 3.682                                         \\\\\n",
    "\\rowcolor[HTML]{D9E1F2} \n",
    "3                              & 9.488                                                             & 3.735                                      & 2.124                                         \\\\\n",
    "4                              & 11.07                                                             & 4.255                                      & 4.525                                         \\\\\n",
    "\\rowcolor[HTML]{D9E1F2} \n",
    "5                              & 12.592                                                            & 2.86                                       & 6.345                                         \\\\\n",
    "6                              & 14.067                                                            & 4.071                                      & 6.377                                         \\\\\n",
    "\\rowcolor[HTML]{D9E1F2} \n",
    "7                              & 15.507                                                            & 8.662                                      & 11.731                                        \\\\\n",
    "8                              & 16.919                                                            & 14.426                                     & 8.693                                         \\\\\n",
    "\\rowcolor[HTML]{D9E1F2} \n",
    "9                              & 18.307                                                            & 11.732                                     & 6.932                                         \\\\\n",
    "10                             & 19.675                                                            & 9.857                                      & 5.939                                         \\\\\n",
    "\\rowcolor[HTML]{D9E1F2} \n",
    "11                             & 21.026                                                            & 10.438                                     & 11.73                                         \\\\\n",
    "12                             & 22.362                                                            & 10.985                                     & 15.543                                        \\\\\n",
    "\\rowcolor[HTML]{D9E1F2} \n",
    "13                             & 23.685                                                            & 22.603                                     & 12.022                                        \\\\\n",
    "14                             & 24.996                                                            & 13.988                                     & 12.923                                        \\\\\n",
    "\\rowcolor[HTML]{D9E1F2} \n",
    "15                             & 26.296                                                            & 15.526                                     & 20.71                                         \\\\\n",
    "16                             & 27.587                                                            & 16.288                                     & 11.501                                        \\\\\n",
    "\\rowcolor[HTML]{D9E1F2} \n",
    "17                             & 28.869                                                            & \\cellcolor[HTML]{F8CBAD}32.26              & 12.478                                        \\\\\n",
    "18                             & 30.144                                                            & \\cellcolor[HTML]{F8CBAD}31.787             & 13.882                                       \n",
    "\\end{tabular}\n",
    "\\end{table}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, both generators pass the $\\chi^2$ test and we do not have to reject our null hypothesis $H_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually, we can examine the generated buckets of both random generators in [TODO] the following plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mers = \"mersenne_\"\n",
    "xoshiro = \"xoshiro_\"\n",
    "csv = \".csv\"\n",
    "angle = \"alpha\"\n",
    "name_angles = \"angles\"\n",
    "\n",
    "mers_random_angle = pd.read_csv(path + mers + name_angles + csv)\n",
    "angle_mers = mers_random_angle[angle]\n",
    "xs_random_angle = pd.read_csv(path + xoshiro + name_angles + csv)\n",
    "angle_xs = xs_random_angle[angle]\n",
    "\n",
    "with sns.plotting_context(sns.set()):\n",
    "    x_size_per_plot = 7\n",
    "    y_size_per_plot = 4\n",
    "    rows = 4\n",
    "    cols = 2\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(x_size_per_plot * cols, y_size_per_plot * rows))\n",
    "    cols = [\"Mersenne Twister\", \"xoshiro256++\"]\n",
    "    for ax, col in zip(axes[0], cols):\n",
    "        ax.annotate(col, xy=(0.5, 1), xytext=(0, 10),\n",
    "                    textcoords='offset points', xycoords='axes fraction',\n",
    "                    size='24', ha='center', va='baseline')\n",
    "\n",
    "    axes[0,0].set_xlabel(\"5 buckets\")\n",
    "    axes[0,0].set_ylabel(\"frequency of angle\")\n",
    "    axes[0,0].hist(x=angle_mers,bins = 5)\n",
    "\n",
    "    axes[0,1].set_xlabel(\"5 buckets\")\n",
    "    axes[0,1].hist(x=angle_xs, bins = 5)\n",
    "\n",
    "    axes[1,0].set_xlabel(\"10 buckets\")\n",
    "    axes[1,0].set_ylabel(\"frequency of angle\")\n",
    "    axes[1,0].hist(x=angle_mers,bins = 10)\n",
    "\n",
    "    axes[1,1].set_xlabel(\"10 buckets\")\n",
    "    axes[1,1].hist(x=angle_xs, bins = 10)\n",
    "\n",
    "    axes[2,0].set_xlabel(\"50 buckets\")\n",
    "    axes[2,0].set_ylabel(\"frequency of angle\")\n",
    "    axes[2,0].hist(x=angle_mers,bins = 50)\n",
    "\n",
    "    axes[2,1].set_xlabel(\"50 buckets\")\n",
    "    axes[2,1].hist(x=angle_xs, bins = 50)\n",
    "\n",
    "    axes[3,0].set_xlabel(\"100 buckets\")\n",
    "    axes[3,0].set_ylabel(\"frequency of angle\")\n",
    "    axes[3,0].hist(x=angle_mers,bins = 100)\n",
    "\n",
    "    axes[3,1].set_xlabel(\"100 buckets\")\n",
    "    axes[3,1].hist(x=angle_xs, bins = 100)\n",
    "\n",
    "    plt.savefig(\"Assets/angle_buckets.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![A histogram of different bucket sizes generated by MT and xoshiro256++](Assets/angle_buckets.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mersenne Twister has been known to fail certain statistical tests since its inception, by virtue of its mathematical characteristics. There exist other algorithms that are designed to be faster and that do not fail any known statistical tests, examples of which are almost all of the algorithms in the xoshiro family.[@vigna2019] Ultimately, the xoshiro256++, developed by Sebastian Vigna and David Blackman, was used. It is a variant of the xorshift algorithm, which extends the bit-shift and xor methods by bitrotation, making it still very fast, and more \"random\" than the xorshift.[@wiki:xorshift][@unimi:xoshiro]\n",
    "\n",
    "Note that testing a (pseudo) random number generator is usually much more involved than this, but since this has already been done extensively by other authors, we are satisfied with the $\\chi^2$ test, simply to test the implementation of the xoshiro256++, since it plays an important part.[@wiki:prng][@vigna2019]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Particle Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The particle positions were drawn from a uniform real distribution in the interval $[0, 1)$ for the $x$-coordinate, and $[0, 1)$ for the $y$-coordinate. The velocities were initialized to be in the interval $[-1\\% \\cdot 1, 1\\% \\cdot 1)$ for the $v_x$ component, and $[-1\\% \\cdot 1, 1\\% \\cdot 1)$ for the $v_y$ component. The results can be seen in figure [TODO: figure numbering] below. From the positions in the first row, the velocities in the second row, particle streaming is applied for 1 and 10 timesteps, according to equation (TODO: equ numbering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "path = \"../x64/Debug/Data/RNG/\"\n",
    "mers = \"mersenne_\"\n",
    "xoshiro = \"xoshiro_\"\n",
    "csv = \".csv\"\n",
    "particles = \"particles\"\n",
    "moved_xy = \"_after_move\"\n",
    "timesteps_moved_xy = \"_after_xx_timesteps\"\n",
    "x = \"x\"\n",
    "y = \"y\"\n",
    "vx = \"vx\"\n",
    "vy = \"vy\"\n",
    "\n",
    "mers_particles = pd.read_csv(path + mers + particles + csv)\n",
    "x_mers = mers_particles[x]\n",
    "y_mers = mers_particles[y]\n",
    "vx_mers = mers_particles[vx]\n",
    "vy_mers = mers_particles[vy]\n",
    "\n",
    "xs_particles = pd.read_csv(path + xoshiro + particles + csv)\n",
    "x_xs = xs_particles[x]\n",
    "y_xs = xs_particles[y]\n",
    "vx_xs = xs_particles[vx]\n",
    "vy_xs = xs_particles[vy]\n",
    "\n",
    "mers_moved_particles = pd.read_csv(path + mers + particles + moved_xy + csv)\n",
    "moved_x_mers = mers_moved_particles[x]\n",
    "moved_y_mers = mers_moved_particles[y]\n",
    "moved_vx_mers = mers_moved_particles[vx]\n",
    "moved_vy_mers = mers_moved_particles[vy]\n",
    "\n",
    "xs_moved_particles = pd.read_csv(path + xoshiro + particles + moved_xy + csv)\n",
    "moved_x_xs = xs_moved_particles[x]\n",
    "moved_y_xs = xs_moved_particles[y]\n",
    "moved_vx_xs = xs_moved_particles[vx]\n",
    "moved_vy_xs = xs_moved_particles[vy]\n",
    "\n",
    "mers_timesteps_moved_particles = pd.read_csv(path + mers + particles + timesteps_moved_xy + csv)\n",
    "timesteps_moved_x_mers = mers_timesteps_moved_particles[x]\n",
    "timesteps_moved_y_mers = mers_timesteps_moved_particles[y]\n",
    "timesteps_moved_vx_mers = mers_timesteps_moved_particles[vx]\n",
    "timesteps_moved_vy_mers = mers_timesteps_moved_particles[vy]\n",
    "\n",
    "xs_timesteps_moved_particles = pd.read_csv(path + xoshiro + particles + timesteps_moved_xy + csv)\n",
    "timesteps_moved_x_xs = xs_timesteps_moved_particles[x]\n",
    "timesteps_moved_y_xs = xs_timesteps_moved_particles[y]\n",
    "timesteps_moved_vx_xs = xs_timesteps_moved_particles[vx]\n",
    "timesteps_moved_vy_xs = xs_timesteps_moved_particles[vy]\n",
    "\n",
    "\n",
    "with sns.plotting_context(sns.set()):\n",
    "    point_size = 0.01\n",
    "    x_size_per_plot = 7\n",
    "    y_size_per_plot = 4\n",
    "    rows = 4\n",
    "    cols = 2\n",
    "    #plt.figure(num = 1, figsize=(x_size_per_plot * cols, y_size_per_plot * rows))\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(x_size_per_plot * cols, y_size_per_plot * rows))\n",
    "    cols = [\"Mersenne Twister\", \"xoshiro256++\"]\n",
    "    for ax, col in zip(axes[0], cols):\n",
    "        ax.annotate(col, xy=(0.5, 1), xytext=(0, 10),\n",
    "                    textcoords='offset points', xycoords='axes fraction',\n",
    "                    size='24', ha='center', va='baseline')\n",
    "\n",
    "    axes[0,0].set_ylabel(y)\n",
    "    axes[0,0].plot(x_mers, y_mers, \"o\", markersize = point_size)\n",
    "    axes[0,0].set_xlabel(x)\n",
    "\n",
    "    axes[0,1].plot(x_xs, y_xs, \"o\", markersize = point_size)\n",
    "    axes[0,1].set_xlabel(x)\n",
    "\n",
    "    axes[1,0].set_ylabel(\"y-component of v\")\n",
    "    axes[1,0].plot(vx_mers, vy_mers, \"o\", markersize = point_size)\n",
    "    axes[1,0].set_xlabel(\"x-component of v\")\n",
    "\n",
    "    axes[1,1].plot(vx_xs, vy_xs, \"o\", markersize = point_size)\n",
    "    axes[1,1].set_xlabel(\"x-component of v\")\n",
    "\n",
    "    axes[2,0].set_ylabel(y)\n",
    "    axes[2,0].plot(moved_x_mers, moved_y_mers, \"o\", markersize = point_size)\n",
    "    axes[2,0].set_xlabel(x)\n",
    "\n",
    "    axes[2,1].plot(moved_x_xs, moved_y_xs, \"o\", markersize = point_size)\n",
    "    axes[2,1].set_xlabel(x)\n",
    "\n",
    "    axes[3,0].set_ylabel(y)\n",
    "    axes[3,0].plot(timesteps_moved_x_mers, timesteps_moved_y_mers, \"o\", markersize = point_size)\n",
    "    axes[3,0].set_xlabel(x)\n",
    "\n",
    "    axes[3,1].plot(timesteps_moved_x_xs, timesteps_moved_y_xs, \"o\", markersize = point_size)\n",
    "    axes[3,1].set_xlabel(x)\n",
    "\n",
    "    plt.savefig(\"Assets/particle_streaming.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Particle streaming without collision with MT and with xoshiro](Assets/particle_streaming.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the x and y coordinates are randomly initialized according to the shape of the container. Looking closely, one can see that our particles look very much like noise. The absolute value of the velocity components are initialized to at most 1% of their respective dimensions. After one timestep, some of the particles on the outer ranges have moved out of bounds, and after ten timesteps, the particles have thinned out considerably along the edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The collision step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the implementation of the collision step, a regular lattice, is needed. This grid has lattice constant $a$, where $a$ is a function of the desired average number of particles per cell, which is typically initialised to between three and 20[@winkl2009], although it can be as high as 70[@ihlekroll2001].\n",
    "\n",
    "The lattice constant $a$ is calculated as follows. The average number of particles per cell, $\\bar{N_c}$, is decided upon. If the grid has fixed dimensions, the number of cells is $n = \\frac{N}{\\bar{N_c}}$. This assumption is valid when only looking at flow through the region of interest and simulating continuous, neverending flow. Practically, this means ignoring particles that go too far out of this region of interest and creating particles that flow into it. If we assign a width $w$ and height $h$ to our region of interest, its area is $A = wh$. But since $n a^{2} = A$, this means that $a = \\sqrt{\\frac{wh}{n}}$. In figure (TODO), a visual representation of this setup can be seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "path = '../x64/Debug/Data/CellFrequenciesTest/'\n",
    "csv = '.csv'\n",
    "name_frequencies = 'cell_frequencies_av'\n",
    "row = 'i'\n",
    "col = 'j'\n",
    "num = 'n'\n",
    "name_constants = 'constants_'\n",
    "average_particles = 'average_particles_per_cell'\n",
    "number_particles = 'total_number_of_particles'\n",
    "cell_dim = 'cell_dim'\n",
    "\n",
    "filenames_f = glob.glob('{}{}*{}'.format(path, name_frequencies, csv))\n",
    "filenames_c = glob.glob('{}{}*{}'.format(path, name_constants, csv))\n",
    "\n",
    "# get frequencies, sort by len\n",
    "pivots = []\n",
    "for file in filenames_f:\n",
    "    temp = pd.read_csv(file)\n",
    "    temp = temp[temp[row] != temp[row].max()]\n",
    "    temp = temp[temp[col] != temp[col].max()]\n",
    "    pivot = temp.pivot(index = row, columns = col, values = num)\n",
    "    pivots.append(pivot)\n",
    "pivots.sort(key=lambda l: len(l), reverse=True)\n",
    "    \n",
    "# get constants, sort by av_particles (same sort as above)\n",
    "info_df = pd.DataFrame(columns=['timesteps','time_lapse','cell_dim','x_0','y_0','x_max','y_max','average_particles_per_cell','total_number_of_particles'])\n",
    "for file in filenames_c:\n",
    "    info_df = pd.concat([info_df, pd.read_csv(file)], ignore_index=True)\n",
    "info_df = info_df.sort_values(average_particles)\n",
    "num = info_df[number_particles]\n",
    "average = info_df[average_particles]\n",
    "a = info_df[cell_dim]\n",
    "width = info_df['x_max'] - info_df['x_0']\n",
    "height = info_df['y_max'] - info_df['y_0']\n",
    "\n",
    "# plot data\n",
    "fig, ax = plt.subplots(2, 2, figsize = (15,10))\n",
    "fig.tight_layout(pad=3.0)\n",
    "\n",
    "ax[0,0].set_title('Particles: {p}, Average: {av}, a={a}, w={w}, h={h}'.format(p = int(num.iloc[0]),\n",
    "                                                                                       av = int(average.iloc[0]),\n",
    "                                                                                       a = round(float(a.iloc[0]), 3), \n",
    "                                                                                       w = round(float(width[0]), 3), \n",
    "                                                                                       h = round(float(height[0]), 3)))\n",
    "sns.heatmap(pivots[0], ax = ax[0,0])#, ax=ax1)\n",
    "ax[0,1].set_title('Particles: {p}, Average: {av}, a={a}, w={w}, h={h}'.format(p = int(num.iloc[1]),\n",
    "                                                                                       av = int(average.iloc[1]),\n",
    "                                                                                       a = round(float(a.iloc[1]), 3), \n",
    "                                                                                       w = round(float(width[1]), 3), \n",
    "                                                                                       h = round(float(height[1]), 3)))\n",
    "sns.heatmap(pivots[1], ax = ax[0,1])#, ax=ax2)\n",
    "ax[1,0].set_title('Particles: {p}, Average: {av}, a={a}, w={w}, h={h}'.format(p = int(num.iloc[2]),\n",
    "                                                                                       av = int(average.iloc[2]),\n",
    "                                                                                       a = round(float(a.iloc[2]), 3), \n",
    "                                                                                       w = round(float(width[2]), 3), \n",
    "                                                                                       h = round(float(height[2]), 3)))\n",
    "sns.heatmap(pivots[2], ax = ax[1,0])\n",
    "ax[1,1].set_title('Particles: {p}, Average: {av}, a={a}, w={w}, h={h}'.format(p = int(num.iloc[3]),\n",
    "                                                                                       av = int(average.iloc[3]),\n",
    "                                                                                       a = round(float(a.iloc[3]), 3), \n",
    "                                                                                       w = round(float(width[3]), 3), \n",
    "                                                                                       h = round(float(height[3]), 3)))\n",
    "sns.heatmap(pivots[3], ax = ax[1,1])\n",
    "\n",
    "plt.savefig(\"Assets/average_grid_particles.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Average number of particles per Grid cell](Assets/average_grid_particles.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we might speculate as to the effects of different average cell particles. When the average number is higher, the collision might be more crude ??????????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After particle streaming, a random shift is introduced. Its components are sampled from a uniform random distribution in the interval $[-\\frac{a}{2},\\frac{a}{2}]$. The random shift is the same for all particles, but usually differs from timestep to timestep. As discussed before, this step is necessary to restore the Galilean invariance that is violated when the molecular chaos assumption does not hold, which happens when simulating cold fluids or when using very small timesteps.[@ihlekroll2001]\n",
    "The shift is undone at the end of the collision step, after the velocity of a particle has been updated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Velocity updating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The velocities of the particles update according to equation (TODO: numbering equ). To calculate the mean velocity $\\vec{V_{c}}$ of cell $c$, first a way to assign each particle a cell has to be established. Let the indices of the cell be $(i, j)$. The position of a cell can then be calculated as $x_c = j \\cdot a$ and $y_c = i \\cdot a$, where a is the lattice constant. This is implemented using the quite straightforward rule\n",
    "\n",
    "\\begin{equation}\n",
    "i = \\floor{\\frac{y}{a}}\\\\\n",
    "j = \\floor{\\frac{x}{a}},\n",
    "\\end{equation}\n",
    "where $(x,y)$ refers to the components of the particle's position vector. With this method to determine the cells, the total cell velocities and numbers of particles in each cell are calculated to obtain the mean cell velocity. Using a randomly sampled rotation angle \\alpha and rule (TODO: numbering equ), the particles' velocities are updated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing MPCD barebones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having implemented the essential features of the MPCD algorithm, it is time for testing it to make sure it was implemented correctly. This section will present conservation tests and visual tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timestep animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To inspect and understand the behavior of our simulation, an animation was created. The fluid starts out in a random state, which means that the positions and velocities of the particles are initialized randomly. From a confusing, chaotic start, a pattern emerges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An animation of the simulated timesteps can be seen below in figure (Todo). The region shown is inmidst fluid. (pressure from all sides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = []\n",
    "I = []\n",
    "J = []\n",
    "U = []\n",
    "V = []\n",
    "pivot = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import os.path\n",
    "\n",
    "path = \"../Application/MPCDApplication/Data/\"\n",
    "csv = \".csv\"\n",
    "constants = 'constants_av' + str(av) + csv\n",
    "\n",
    "constants_av20 = pd.read_csv(path + constants)\n",
    "num_timesteps = int(constants_av20['timesteps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found saved particles_x and particles_y files!\n",
      "Loaded particles files.\n",
      "              x0        x1        x2        x3        x4        x5        x6  \\\n",
      "6       0.982265       NaN       NaN       NaN       NaN  0.914297  0.902569   \n",
      "10      0.663660       NaN       NaN       NaN  0.811696  0.822963       NaN   \n",
      "11      0.893975  0.816794       NaN  0.812675  0.758183       NaN       NaN   \n",
      "12      0.742318       NaN  0.823057  0.759162       NaN  0.769449       NaN   \n",
      "13      0.968081       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "499976  0.475192       NaN       NaN  0.322494       NaN       NaN  0.321054   \n",
      "499979  0.267292       NaN  0.488172  0.773291       NaN       NaN  0.771851   \n",
      "499980  0.469811  0.685855       NaN       NaN  0.680758  0.692024       NaN   \n",
      "499987  0.164289  0.923245  0.618624  0.156441  0.918148  0.929414  0.155001   \n",
      "499998  0.128475  0.078358       NaN  0.120627  0.073261  0.084527  0.119187   \n",
      "\n",
      "              x7        x8        x9  ...      x990      x991      x992  \\\n",
      "6            NaN  0.913645  0.913523  ...       NaN  0.669938       NaN   \n",
      "10           NaN       NaN       NaN  ...       NaN  0.903296  0.818233   \n",
      "11           NaN  0.822310       NaN  ...       NaN  0.811961       NaN   \n",
      "12           NaN  0.768797  0.822189  ...  0.769726       NaN  0.764719   \n",
      "13      0.758018       NaN  0.768675  ...       NaN  0.758448       NaN   \n",
      "...          ...       ...       ...  ...       ...       ...       ...   \n",
      "499976       NaN       NaN  0.155872  ...       NaN       NaN  0.504123   \n",
      "499979  0.714612  0.855483       NaN  ...       NaN       NaN  0.604429   \n",
      "499980       NaN       NaN       NaN  ...  0.330126  0.477077       NaN   \n",
      "499987  0.844704       NaN  0.487305  ...       NaN       NaN       NaN   \n",
      "499998  0.557271  0.568049       NaN  ...       NaN       NaN  0.563972   \n",
      "\n",
      "            x993      x994      x995      x996      x997      x998      x999  \n",
      "6            NaN  0.902488       NaN       NaN  0.910051       NaN       NaN  \n",
      "10           NaN  0.811154       NaN       NaN  0.818717       NaN       NaN  \n",
      "11           NaN       NaN  0.469479       NaN       NaN  0.810913  0.814883  \n",
      "12           NaN  0.757640  0.821265       NaN       NaN       NaN       NaN  \n",
      "13      0.768319       NaN       NaN  0.767138  0.765203  0.757399  0.761369  \n",
      "...          ...       ...       ...       ...       ...       ...       ...  \n",
      "499976       NaN       NaN  0.331084  0.584954       NaN  0.653764       NaN  \n",
      "499979  0.613594       NaN  0.781881       NaN       NaN  0.148141       NaN  \n",
      "499980       NaN  0.259235       NaN       NaN       NaN       NaN  0.022609  \n",
      "499987  0.159061  0.847251  0.165031       NaN       NaN       NaN       NaN  \n",
      "499998  0.083397  0.556893  0.129217  0.566390       NaN  0.118864       NaN  \n",
      "\n",
      "[125126 rows x 1000 columns]\n",
      "              y0        y1        y2        y3        y4        y5        y6  \\\n",
      "6       0.165004       NaN       NaN       NaN       NaN  0.919198  0.911295   \n",
      "10      0.992735       NaN       NaN       NaN  0.435471  0.434226       NaN   \n",
      "11      0.112266  0.436015       NaN  0.430456  0.260662       NaN       NaN   \n",
      "12      0.572194       NaN  0.431797  0.255647       NaN  0.259417       NaN   \n",
      "13      0.828577       NaN       NaN       NaN       NaN       NaN       NaN   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "499976  0.504216       NaN       NaN  0.226697       NaN       NaN  0.222564   \n",
      "499979  0.297557       NaN  0.317567  0.065322       NaN       NaN  0.061188   \n",
      "499980  0.957672  0.306292       NaN       NaN  0.305748  0.304503       NaN   \n",
      "499987  0.206254  0.789234  0.312016  0.199943  0.788691  0.787445  0.195810   \n",
      "499998  0.245764  0.935806       NaN  0.239453  0.935262  0.934017  0.235320   \n",
      "\n",
      "              y7        y8        y9  ...      y990      y991      y992  \\\n",
      "6            NaN  0.922320  0.917922  ...       NaN  0.771608       NaN   \n",
      "10           NaN       NaN       NaN  ...       NaN  0.917746  0.428793   \n",
      "11           NaN  0.437348       NaN  ...       NaN  0.432774       NaN   \n",
      "12           NaN  0.262539  0.432950  ...  0.255432       NaN  0.253984   \n",
      "13      0.251285       NaN  0.258141  ...       NaN  0.257965       NaN   \n",
      "...          ...       ...       ...  ...       ...       ...       ...   \n",
      "499976       NaN       NaN  0.986835  ...       NaN       NaN  0.976078   \n",
      "499979  0.983304  0.168019       NaN  ...       NaN       NaN  0.556182   \n",
      "499980       NaN       NaN       NaN  ...  0.409612  0.318544       NaN   \n",
      "499987  0.156764       NaN  0.318720  ...       NaN       NaN       NaN   \n",
      "499998  0.714579  0.725833       NaN  ...       NaN       NaN  0.717277   \n",
      "\n",
      "            y993      y994      y995      y996      y997      y998      y999  \n",
      "6            NaN  0.917457       NaN       NaN  0.918612       NaN       NaN  \n",
      "10           NaN  0.432485       NaN       NaN  0.433640       NaN       NaN  \n",
      "11           NaN       NaN  0.607260       NaN       NaN  0.436762  0.435627  \n",
      "12           NaN  0.257676  0.427802       NaN       NaN       NaN       NaN  \n",
      "13      0.261528       NaN       NaN  0.254125  0.258831  0.261953  0.260819  \n",
      "...          ...       ...       ...       ...       ...       ...       ...  \n",
      "499976       NaN       NaN  0.224043  0.651687       NaN  0.810569       NaN  \n",
      "499979  0.248054       NaN  0.062667       NaN       NaN  0.177846       NaN  \n",
      "499980       NaN  0.040627       NaN       NaN       NaN       NaN  0.646812  \n",
      "499987  0.177421  0.558873  0.197288       NaN       NaN       NaN       NaN  \n",
      "499998  0.936128  0.720969  0.236798  0.717418       NaN  0.245759       NaN  \n",
      "\n",
      "[125126 rows x 1000 columns]\n"
     ]
    }
   ],
   "source": [
    "chunksize = 10 ** 5\n",
    "shown_x = 1\n",
    "shown_y = 1\n",
    "\n",
    "def load_particles(path, chunksize):\n",
    "    saved = './Saved'\n",
    "    saved_particles_x = '/particles_x.pkl'\n",
    "    saved_particles_y = '/particles_y.pkl'\n",
    "    file_particles_x = saved + saved_particles_x\n",
    "    file_particles_y = saved + saved_particles_y\n",
    "\n",
    "    \n",
    "    x_columns = ['x{}'.format(it) for it in range(0, num_timesteps)]\n",
    "    y_columns = ['y{}'.format(it) for it in range(0, num_timesteps)]\n",
    "    particles_x = pd.DataFrame(columns = x_columns)\n",
    "    particles_y = pd.DataFrame(columns = y_columns)\n",
    "\n",
    "    if (os.path.isfile(file_particles_x) and os.path.isfile(file_particles_y)):\n",
    "        print('Found saved particles_x and particles_y files!')\n",
    "        particles_x = pd.read_pickle(file_particles_x)\n",
    "        particles_y = pd.read_pickle(file_particles_y)\n",
    "        print('Loaded particles files.')\n",
    "    else:\n",
    "        # Loading particles\n",
    "        print('Loading particles ..')\n",
    "        filenames_particles = glob.glob('{}*.csv'.format(path))\n",
    "        it = 0\n",
    "        for file in filenames_particles:\n",
    "            chunks = pd.DataFrame(columns = ['x', 'y'])\n",
    "            for chunk in pd.read_csv(file, chunksize = chunksize):\n",
    "                chunk = chunk.loc[(chunk[x] >= 0) & (chunk[x] <= shown_x) & (chunk[y] >= 0) & (chunk[y] <= shown_y)]\n",
    "                chunks = chunks.append(chunk)\n",
    "                #print(chunks.head())\n",
    "            particles_x['x{}'.format(it)] = chunks['x']\n",
    "            #print(particles_x.head())\n",
    "            particles_y['y{}'.format(it)] = chunks['y']\n",
    "            it += 1\n",
    "            if (it % 100 == 0):\n",
    "                print('--loaded {}'.format(it))\n",
    "        particles_x.to_pickle(file_particles_x)\n",
    "        particles_y.to_pickle(file_particles_y)\n",
    "        it = 0\n",
    "        print('Particles loaded and saved!\\n')\n",
    "        # Particles loaded\n",
    "    return particles_x, particles_y\n",
    "\n",
    "av = 20\n",
    "particles_path = '{parent}particles_av{av}'.format(parent = path, av=av)    \n",
    "particles_x, particles_y = load_particles(path = particles_path, chunksize = chunksize)\n",
    "particles_x.to_csv('{}/particles_x.csv'.format(saved))\n",
    "print(particles_x)\n",
    "print(particles_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cells(path, columns, shown_rows, shown_cols):\n",
    "    saved = './Saved'\n",
    "    saved_cells = '/cells.pkl'\n",
    "    file_cells = saved + saved_cells\n",
    "    if (os.path.isfile(file_cells)):\n",
    "        cells = pd.read_tickle(file_cells)\n",
    "    else:\n",
    "        # Loading cells\n",
    "        print('Loading cells')\n",
    "        \n",
    "        index = 't'\n",
    "        cells = pd.DataFrame(index = index, columns = columns)\n",
    "        \n",
    "        it = 0\n",
    "        filenames_cells = glob.glob('{}*.csv'.format(path))\n",
    "        for file in filenames_cells:\n",
    "            df = pd.read_csv(file)\n",
    "            df = df.loc[(df[i] >= 0) & (df[i] < shown_rows)]\n",
    "            df = df.loc[(df[j] >= 0) & (df[j] < shown_cols)]\n",
    "            df['t'] = it\n",
    "            cells.append(df)\n",
    "            #df[[i,j]] = (df[[i,j]] + 1/2) * cell_dim\n",
    "            \n",
    "            it += 1\n",
    "            if (it % 100 == 0):\n",
    "                print('--loaded {}'.format(it))\n",
    "        cells.to_pickle(file_cells)\n",
    "        print('Cells loaded and saved!\\n')\n",
    "        # Cells loaded\n",
    "        return cells\n",
    "\n",
    "cell_dim = float(constants_av20['cell_dim'])\n",
    "width = float(constants_av20['x_max']) - float(constants_av20['x_0'])\n",
    "height = float(constants_av20['y_max']) - float(constants_av20['y_0'])\n",
    "shown_cols = floor(width / cell_dim)\n",
    "shown_rows = floor(height / cell_dim)\n",
    "cells_path = path + 'cells_av{}'.format(av)\n",
    "\n",
    "columns = ['i', 'j', 'vx', 'vy', 'num']\n",
    "cells = load_cells(cell_path, columns, shown_rows, shown_cols)\n",
    "I,J,U,V,pivots = prepare_cells(cells, columns, shown_rows, shown_cols)\n",
    "\n",
    "def prepare_cells(cells, columns, shown_rows, shown_cols):\n",
    "    # Preparing cell values\n",
    "    print('Preparing cell values ..')\n",
    "\n",
    "    array_i = np.arange(0, shown_rows)\n",
    "    array_j = np.arange(0, shown_cols)\n",
    "    I,J = np.meshgrid(array_i, array_j)\n",
    "\n",
    "    U = []\n",
    "    V = []\n",
    "\n",
    "    i = columns[0]\n",
    "    j = columns[1]\n",
    "    vx = columns[2]\n",
    "    vy = columns[3]\n",
    "    num = columns[4]\n",
    "\n",
    "    for t in cells.index:\n",
    "        # only the rows and cols above 0\n",
    "        # and below shown_rows, shown_cols\n",
    "        # this is to \n",
    "        # --1. no vaccuum around simulated region\n",
    "        # --2. I,J are fixed size\n",
    "        df = cells.iloc[t]\n",
    "        U_inner = []\n",
    "        V_inner = []\n",
    "        for it in array_i: # TODO: check this code something seems foul (row, cols, but only using rows)\n",
    "            temp = df.loc[df[i] == it]\n",
    "            u = np.array(temp[vx])\n",
    "            U_inner.append(u)\n",
    "            v = np.array(temp[vy])\n",
    "            V_inner.append(v)\n",
    "        U.append(np.array(U_inner))\n",
    "        V.append(np.array(V_inner))\n",
    "\n",
    "        pivot = df.pivot(index = i, columns = j, values = num)\n",
    "        pivots.append(pivot)\n",
    "\n",
    "    print('Cell preparation complete!\\n')\n",
    "    return I,J,U,V, pivots\n",
    "    # Cell preparation complete\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plotting\n",
    "#with (sns.plotting_context(sns.set())):\n",
    "print('Plotting data ..')\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "ax = [fig.add_subplot(2,2,i+1) for i in range(4)]\n",
    "\n",
    "for a in ax:\n",
    "    a.set_xticklabels([])\n",
    "    a.set_yticklabels([])\n",
    "    a.set_aspect('equal')\n",
    "    \n",
    "fig.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "color = np.sqrt(U[0]**2 + V[0]**2)\n",
    "point_size = 1\n",
    "\n",
    "print(U)\n",
    "\n",
    "ax[0].xaxis.set_ticks([])\n",
    "ax[0].yaxis.set_ticks([])\n",
    "ax[0].quiver(I, J, U[0], V[0], color, scale = 0.4)\n",
    "\n",
    "ax[1].xaxis.set_ticks([])\n",
    "ax[1].yaxis.set_ticks([])\n",
    "ax[1].streamplot(I, J, U[0], V[0], ) # grid\n",
    "\n",
    "ax[2].xaxis.set_ticks([])\n",
    "ax[2].yaxis.set_ticks([])\n",
    "ax[2].plot(particles_x['x0'], particles_y['y0'], \"o\", markersize = point_size)\n",
    "\n",
    "ax[3].xaxis.set_ticks([])\n",
    "ax[3].yaxis.set_ticks([])\n",
    "#img = ax[3].imshow(pivot, cmap='hot')\n",
    "#fig.colorbar(img, ax=ax[3], fraction=0.046, pad=0.005)\n",
    "sns.heatmap(pivot, ax=ax[3], xticklabels = False, yticklabels = False, cbar_kws={\"fraction\": 0.046, \"pad\": 0.005})\n",
    "#ax[3].xticks('')\n",
    "#ax[3].yticks('')\n",
    "ax[3].set_ylabel('')\n",
    "ax[3].set_xlabel('')\n",
    "#ax[1,1].imshow(pivot, cmap='hot')\n",
    "\n",
    "#plt.savefig(\"Assets/timesteps.png\")\n",
    "#plt.close()\n",
    "print('Data plotted!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "\n",
    "# First set up the figure, the axis, and the plot element we want to animate\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(xlim=(0, shown_cols), ylim=(0, shown_rows))\n",
    "\n",
    "quiv = ax.quiver(I, J, U[0], V[0], color, scale = 0.4)\n",
    "\n",
    "# initialization function: plot the background of each frame\n",
    "def init():\n",
    "    #quiv.set_data([], [], [], [])\n",
    "    return quiv,\n",
    "\n",
    "# animation function.  This is called sequentially\n",
    "def animate(it):\n",
    "    color = np.sqrt(U[it]**2 + V[it]**2)\n",
    "    quiv.set_UVC(U[it], V[it])\n",
    "    return quiv,\n",
    "\n",
    "# call the animator.  blit=True means only re-draw the parts that have changed.\n",
    "anim = animation.FuncAnimation(fig, animate, #init_func=init,\n",
    "                               frames=1000, interval=5, blit=True)\n",
    "\n",
    "# save the animation as an mp4.  This requires ffmpeg or mencoder to be\n",
    "# installed.  The extra_args ensure that the x264 codec is used, so that\n",
    "# the video can be embedded in html5.  You may need to adjust this for\n",
    "# your system: for more information, see\n",
    "# http://matplotlib.sourceforge.net/api/animation_api.html\n",
    "anim.save('quiver_animation.mp4', fps=30) #extra_args=['-vcodec', 'libx264'])\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "\n",
    "# First set up the figure, the axis, and the plot element we want to animate\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(xlim=(0, shown_cols), ylim=(0, shown_rows))\n",
    "color = np.sqrt(U[0]**2 + V[0]**2)\n",
    "stream = ax.streamplot(I, J, U[0], V[0], color=color)\n",
    "\n",
    "# initialization function: plot the background of each frame\n",
    "def init():\n",
    "    #quiv.set_data([], [], [], [])\n",
    "    return stream\n",
    "\n",
    "# animation function.  This is called sequentially\n",
    "def animate(it):\n",
    "    ax.collections = [] # clear lines streamplot\n",
    "    ax.patches = [] # clear arrowheads streamplot\n",
    "    stream = ax.streamplot(I, J, U[it], V[it], color=color)\n",
    "    return stream\n",
    "\n",
    "# call the animator.  blit=True means only re-draw the parts that have changed.\n",
    "anim = animation.FuncAnimation(fig, animate, #init_func=init,\n",
    "                               frames=1000, interval=5, blit=False)\n",
    "\n",
    "# save the animation as an mp4.  This requires ffmpeg or mencoder to be\n",
    "# installed.  The extra_args ensure that the x264 codec is used, so that\n",
    "# the video can be embedded in html5.  You may need to adjust this for\n",
    "# your system: for more information, see\n",
    "# http://matplotlib.sourceforge.net/api/animation_api.html\n",
    "anim.save('streamplot_animation.mp4', fps=30) #extra_args=['-vcodec', 'libx264'])\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "import seaborn as sns\n",
    "\n",
    "# First set up the figure, the axis, and the plot element we want to animate\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(xlim=(0, shown_cols), ylim=(0, shown_rows))\n",
    "sns.heatmap(pivot, ax=ax, xticklabels = False, yticklabels = False)#,cbar_kws={\"fraction\": 0.046, \"pad\": 0.005})\n",
    "\n",
    "# initialization function: plot the background of each frame\n",
    "def init():\n",
    "    plt.clf()\n",
    "    #return heatmap,\n",
    "\n",
    "# animation function.  This is called sequentially\n",
    "def animate(it):\n",
    "    plt.clf()\n",
    "    heatmap = sns.heatmap(pivots[it], ax=ax, xticklabels = False, yticklabels = False)#,cbar_kws={\"fraction\": 0.046, \"pad\": 0.005})\n",
    "    #return heatmap,\n",
    "\n",
    "# call the animator.  blit=True means only re-draw the parts that have changed.\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=1000, interval=5)\n",
    "\n",
    "# save the animation as an mp4.  This requires ffmpeg or mencoder to be\n",
    "# installed.  The extra_args ensure that the x264 codec is used, so that\n",
    "# the video can be embedded in html5.  You may need to adjust this for\n",
    "# your system: for more information, see\n",
    "# http://matplotlib.sourceforge.net/api/animation_api.html\n",
    "anim.save('heatmap_animation.mp4', fps=30) #extra_args=['-vcodec', 'libx264'])\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "\n",
    "# First set up the figure, the axis, and the plot element we want to animate\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(xlim=(0, 1), ylim=(0, 1))\n",
    "scatter, = ax.plot(particles_x['x0'], particles_y['y0'], \"o\", markersize = point_size)\n",
    "\n",
    "# initialization function: plot the background of each frame\n",
    "def init():\n",
    "    #quiv.set_data([], [], [], [])\n",
    "    return scatter,\n",
    "\n",
    "# animation function.  This is called sequentially\n",
    "def animate(it):\n",
    "    scatter.set_xdata(particles_x[x + str(it)])\n",
    "    scatter.set_ydata(particles_y[y + str(it)])\n",
    "    return scatter,\n",
    "\n",
    "# call the animator.  blit=True means only re-draw the parts that have changed.\n",
    "anim = animation.FuncAnimation(fig, animate, #init_func=init,\n",
    "                               frames=1000, interval=5, blit=True)\n",
    "\n",
    "# save the animation as an mp4.  This requires ffmpeg or mencoder to be\n",
    "# installed.  The extra_args ensure that the x264 codec is used, so that\n",
    "# the video can be embedded in html5.  You may need to adjust this for\n",
    "# your system: for more information, see\n",
    "# http://matplotlib.sourceforge.net/api/animation_api.html\n",
    "anim.save('scatterplot_animation.mp4', fps=30, extra_args=['-vcodec', 'libx264'])\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conservation of momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collision step of the MPCD algorithm should conserve energy & momentum _locally_, (TODO: which is to say on a cell level?). [@winkl2009] To inspect this, the mean velocity of cells\n",
    "\n",
    "\\begin{equation}\n",
    "V_i = V_t,\n",
    "\\end{equation}\n",
    "\n",
    "where $V_i$ is the sum of all initial velocities, and $V_t$ is the sum of all velocities at timestep $t$, of all particles. Since $V_c$, the mean cell velocity, is already needed, we can simply sum them up and divide by the number of cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To inspect this, the total momentum $\\vbar P \\vbar$ is plotted as a function of timestep $t$ in figure (TODO: figures)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "print(U[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conservation of energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because no forces act on the particles, and they all have the same mass, conservation of energy takes the form\n",
    "\n",
    "\\begin{equation}\n",
    "\\sum_{j=0}^{N} \\vect{v_{ij}}^{2} = \\sum_{j=0}^{N} \\vect{v_{tj}}^{2},\n",
    "\\end{equation}\n",
    "\n",
    "where $i$ shall mean _initial_ and $t$ shall mean _timestep t_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To inspect this, the total energy is plotted as a function of timestep $t$ in figure (TODO: figures)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "print(U[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "w = 3\n",
    "Y, X = np.mgrid[-w:w:100j, -w:w:100j]\n",
    "U = -1 - X**2 + Y\n",
    "V = 1 + X - Y**2\n",
    "speed = np.sqrt(U**2 + V**2)\n",
    "\n",
    "fig = plt.figure(figsize=(7, 9))\n",
    "gs = gridspec.GridSpec(nrows=1, ncols=1)\n",
    "\n",
    "#  Varying density along a streamline\n",
    "ax0 = fig.add_subplot(gs[0, 0])\n",
    "ax0.streamplot(X, Y, vx_evolution, vy_evolution, density=[0.5, 1])\n",
    "ax0.set_title('Varying Density')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vx_evolution.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vy_evolution.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To optimize the runtime of the simulation, the code was analyzed for CPU & memory usage. Several areas were identified that needed improvement. In the end, the streaming and collision step are now performed in parallel, with the performance of the latter being very satisfying. The performance of the streaming step however could not be optimized much further. The problem is storage shared between threads, which means, to prevent errors and undefinable behavior, the program can't make full use of parallelization. It was tried to split this shared storage and later recombine, but this was to no avail. Ultimately, a lot of time was spent on this but unfortunately, the intricacies of C++ made this seem impossible.\n",
    "\n",
    "The reason a lot of time was spent on this particular step is to make possible a larger simulation, i.e. larger number of particles. The simulation at the end will likely be around $10^6$ particles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The velocity of a particle updates according to\n",
    "\\begin{equation}\n",
    "\\vect{v_{i}} \\rightarrow \\vect{V_c} + \\matr{R}(\\alpha)[\\vect{v_i} - \\vect{V_c}],\n",
    "\\end{equation}\n",
    "\n",
    "where $\\vect{v_{i}}$ is the velocity of the $i-th$ particle, $\\vect{V_c}$ is the mean velocity of all particles belonging to cell $c$, specified by $i$'s position. The matrix\n",
    "\n",
    "$$\n",
    "R(\\alpha) = \n",
    "\\left[ \\begin{array}{rr}\n",
    "cos(\\alpha) & -sin(\\alpha) \\\\\n",
    "sin(\\alpha) & cos(\\alpha) \\\\\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "is a simple 2d-rotation matrix. The angle $\\alpha$ is uniformly sampled from the interval $[0, 2\\pi)$ on a per-cell basis.[@malev1999]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONSIDER THIS. SHOULD BECOME MAXWELL WHEN IMPLEMENTING COLLISION STEP TOO\n",
    "After having implemented the streaming step and that other one: after time driftting, looks like this: (+velocity distribution = maxwell?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some equations to copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "r(t + \\Delta t) = r(t) + \\Delta t \\cdot v(t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to Word doc (others possible too, f.ex. .tex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just do it manually, it works on anaconda env datascience\n",
    "\n",
    "import subprocess\n",
    "#automatic document conversion to markdown and then to word\n",
    "#first convert the ipython notebook paper.ipynb to markdown\n",
    "subprocess.run(\"jupyter nbconvert --to markdown thesis.ipynb --output-dir='./Generated'\") #--output-dir='./Generated'\n",
    "#next remove code\n",
    "path = \"./Generated/thesis.md\"\n",
    "with open(path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    idx = []\n",
    "    idx_files = []\n",
    "    for i, line in enumerate(lines):\n",
    "        if (line.startswith(\"```\")):\n",
    "            idx.append(i)\n",
    "        if (\"thesis_files\" in line):\n",
    "            c = line.find(\"thesis_files\")\n",
    "            lines[i] = line[0:c] + \"\" + line[c:]\n",
    "\n",
    "idx = sorted(idx, reverse=True) # reverse order so not deleting lines and then missing others\n",
    "for current, previous in zip(idx[::2], idx[1::2]):\n",
    "    print(\"Deleting {p}:{c}\".format(p=previous, c=current+1))\n",
    "    print('\\n'.join(lines[previous:current+1]))\n",
    "    del lines[previous:current+1]\n",
    "    \n",
    "with open(path, \"w\") as f:\n",
    "    #f.write(\"\\\\newcommand{\\matr}[1]\\\\textbf{#1}\")\n",
    "    #f.write(\"\\\\newcommand{\\\\vect}[1]{\\\\vec{#1}}\")\n",
    "    for line in lines:\n",
    "        f.write(\"%s\" % line)\n",
    "#next convert markdown to ms word\n",
    "conversion_tex = \"pandoc -s ./Generated/thesis.md -o ./Generated/thesis.tex --filter pandoc-citeproc --bibliography=\\\"list.bib\\\" --csl=\\\"apa.csl\\\"\"\n",
    "subprocess.run(conversion_tex)\n",
    "conversion_pdf = \"pandoc -s ./Generated/thesis.md -o ./Generated/thesis.pdf --filter pandoc-citeproc --bibliography=\\\"list.bib\\\" --csl=\\\"apa.csl\\\"\"\n",
    "subprocess.run(conversion_pdf)\n",
    "# LATEX TO DOCX pandoc -s math.tex -o example30.docx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equation Numbering jupyter extension\n",
    "conda install -c conda-forge jupyter_contrib_nbextensions\n",
    "\n",
    "jupyter contrib nbextension install --user\n",
    "\n",
    "jupyter nbextension enable equation-numbering/main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn equation numbering on/off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "MathJax.Hub.Config({\n",
    "    TeX: { equationNumbers: { autoNumber: \"AMS\" } }\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renumber equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "MathJax.Hub.Queue(\n",
    "  [\"resetEquationNumbers\", MathJax.InputJax.TeX],\n",
    "  [\"PreProcess\", MathJax.Hub],\n",
    "  [\"Reprocess\", MathJax.Hub]\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
