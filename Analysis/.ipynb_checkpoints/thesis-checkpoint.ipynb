{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\newcommand{\\matr}[1]\\textbf{#1}\n",
       "\\newcommand{\\vect}[1]{\\vec{#1}}\n",
       "\\usepackage[table,xcdraw]{xcolor}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\newcommand{\\matr}[1]\\textbf{#1}\n",
    "\\newcommand{\\vect}[1]{\\vec{#1}}\n",
    "\\usepackage[table,xcdraw]{xcolor}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To my dear supervisors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dear Professor Likos!\n",
    "Dear Dr. Bianchi!\n",
    "\n",
    "Professor Likos, I hope you're enjoying your vacation.\n",
    "\n",
    "You haven't heard from me in a while because I was on vaction too, but I have started my work on the thesis. \n",
    "I will review what we discussed in person and online with Dr. Bianchi, and I hope you are as interested in the\n",
    "research question as I am. Dr. Bianchi, if you have suggestions for adapting dimensions/parameters of the situation (fluid flow through 2d cross section of pipe with cylindrical obstacles) or even tweak the situation, I would love to hear your suggestions too.\n",
    "I hope I depicted the situation somewhat well below. I thought it would be interesting to not only try obstacles that are\n",
    "regularly spaced, all the same size, but try a more heterogeneous situation. But that is still a little ways down the road,\n",
    "so I'll have to see about that.\n",
    "\n",
    "Progress-wise I'd say I'm still at the beginning. All the work here has been done in about 1 week. I'm working on the collision step now. It took a lot of time to get familiar with C++ again, and to find out how best to test my results. I think I have found a good way to do this, called unit testing, which basically means you test every unit of your program separately and make sure they work under various circumstances, to make debugging easier later down the road and also to add more credibility to my results.\n",
    "\n",
    "Please do not worry if the writing style is sometimes informal, and at other times formal. I meant it to be that way, as some sections are unfinished/jumbled down thoughts/still expanding/experimenting. Also, the citing style is not the final version either, unfortunately, I cannot change it at the moment.\n",
    "\n",
    "I'd be happy to hear your guidance and if everything is looking good, or if you suggest I focus more on other areas. If you have a lot to tell me I'd be happy to meet over Zoom/Teams or in person.\n",
    "\n",
    "Where possible, I've not cited Wikipedia, or added other sources. Is it still okay if I cite Wikipedia, or is that completely undesirable?\n",
    "\n",
    "All the best,\n",
    "\n",
    "Chris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPCD simulation of polymers in solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will serve as the documentation of our efforts and results for my Bachelor's Thesis. The goal of this thesis will be the study of short/long-chained polymers in a liquid thats flowing around obstacles. The liquid will be simulated with MPCD, or \"Multi Particle Collision Dynamics\".\n",
    "\n",
    "I chose the language C++ for its familiar object-oriented nature and its proven execution-time. Output of the simulation will mostly be analysed in Python, specifically with Jupyter Notebook for a blend of beautiful visualizations and convenience. For simplification, the situation will be studied in 2D. The situation we specifically discussed is shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Situation](Assets/MPCD_Situation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open questions & Description of situation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these questions, I need to expand the program to even consider them. If I get close and still have no idea how to go about them, I will contact Maximilian Liebetreu (I think he was there when we first met, I'm sorry I can't remember exactly). Are there other people I can contact for the programming/implementation details?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fluid flows from the -x direction through the 2D cross-section of some vessel. In this vessel there are cylindrically shaped objects, through which the fluid cannot pass. (->How will I simulate the obstacles, are they solid non-deformable, are they soft & elastic, ..?) (-> Methods: create a lot of particles and immobilize them?, check for collision between particles and obstacles on a per particle basis? (this will probably be too expensive computationally))\n",
    "\n",
    "What happens when fluid goes out of bounds? (->Should particles that go too far in the +x direction be destroyed and new ones created from the -x direction, simulating continuous flow?)\n",
    "\n",
    "Finally, polymers will be introduced into the fluid and their behavior studied. We might imagine this \"vessel\" as a blood vessel and the obstacles as cells moving around in the bloodstream, for example. (-> For the polymers, you told me I should wait until the MPCD is really working)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiparticle collision dynamics (MPCD), also known as Stochastic Rotation Dynamics (SRD)[@winkl2009] is a technique originally introduced to study the dynamics of complex fluids such as polymers in solution. Besides MPCD, there exist other mesoscopic models that have been constructed for this purpose, such as Langevin, Direct Simulation Monte Carlo and lattice Boltzmann methods.[@malev1999] We only concern ourselves with the application of MPCD, it follows that any comparison between methods are out of the scope of this thesis.\n",
    "\n",
    "The MPCD technique models the fluid using particles, their positions and velocities are treated as continuous variables. The system is divided up into cells that have no restriction on the number of particles, each of the cells is part of a regular lattice. The dynamics is split into two parts: Particle streaming and multiparticle collision dynamics. Particle streaming is treated exactly for each particle in the system, while the collision step is approximated on a cell level. The multiparticle collision dynamics conserves mass, momentum and energy and leads to the correct hydrodynamical equations.[@malev1999] The streaming and collision step are described in more detail in (TODO: section numbering)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The MPCD algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The system we are modelling consists of $N$ particles with mass $m$, continuous position $\\vec{r_{i}}$ and velocity $\\vec{v_{i}}$, where $i \\in \\{1, 2, \\dots, N\\}$. One timestep $\\Delta t$ shall correspond to having calculated all the new particle positions and velocities in the streaming and collision steps, respectively. For each of the $N$ particles, the streaming and collision steps are applied, and this pattern is repeated until the wanted number of timesteps have elapsed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The streaming step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The streaming step is very straightforward. The particle positions are simply updated according to\n",
    "\n",
    "\\begin{equation}\n",
    "\\vect{r_{i}} \\rightarrow \\vect{r_{i}} + \\Delta t \\cdot \\vect{v_{i}}\\textrm{,}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\Delta t$ is a small time interval.[@winkl2009][@malev1999]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The collision step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collision step is somewhat more complicated. It involves the mean velocity of all particles in a particular cell, $\\vect{V_c}$, the velocity of the particle $i$, $\\vec{v_i}$, and a rotation matrix $\\matr{R}(\\alpha)$. The vector $\\vect{v_i}$ is rotated relative to the mean velocity $\\vect{V_c}$ of all particles in cell $c$, cell $c$ being the cell which particle $i$ belongs to. It is shown in [@malev1999] that the rule,\n",
    "\n",
    "\\begin{equation}\n",
    "\\vect{v_i} \\rightarrow \\vect{V_c} + \\matr{R}(\\alpha) [\\vect{v_i} - \\vect{V_c}] \\textrm{,}\n",
    "\\end{equation}\n",
    "\n",
    "conserves mass, momentum and energy under the molecular chaos assumption[@malev1999][@winkl2009, molecular chaos, p.7]. The rotation matrix $\\matr{R}(\\alpha)$ is a simple 2d rotation matrix\n",
    "\n",
    "\\begin{equation}\n",
    "R(\\alpha) = \n",
    "\\left[ \\begin{array}{rr}\n",
    "cos(\\alpha) & -sin(\\alpha) \\\\\n",
    "sin(\\alpha) & cos(\\alpha) \\\\\n",
    "\\end{array}\\right],\n",
    "\\end{equation}\n",
    "\n",
    "where $\\alpha$ is sampled randomly on a per-cell basis. Furthermore, for each particle in the cell $\\alpha$ flips its sign with probability $\\frac{1}{2}$.[@winkl2009, (p.6)]\n",
    "The mean velocity of a cell is defined as\n",
    "\n",
    "\\begin{equation}\n",
    "\\vect{V_c} = \\frac{1}{N_c} \\sum_{i=1}^{N_c} \\vect{v_i} \\textrm{,}\n",
    "\\end{equation}\n",
    "\n",
    "where $N_c$ is the number of particles in cell c.[@malev1999]\n",
    "\n",
    "The original MPCD algorithm was not Galilean invariant. The problem lay in the \"molecular chaos\" assumption, which means that particles involved in a collision have no memory of earlier encounters when colliding. This assumption is problematic when the mean free path \n",
    "\n",
    "\\begin{equation}\n",
    "\\lambda = \\Delta t \\sqrt{\\frac{k_{B}T}{m}}\n",
    "\\end{equation}\n",
    "\n",
    "is small compared to the cell size $a$, since the same particles collide with each other repeatedly and thus build up correlations. When $\\lambda \\gg a$ Ihle and Kroll have shown that the molecular chaos assumption holds and the simulated results deviate from experimental ones only negligibly.[@ihlekroll2001, p.2][@winkl2009]\n",
    "\n",
    "The solution to this problem is to shift all particles by the same random vector $s$ before the collision step. The components of $s$ are sampled randomly from a uniform distribution in the interval $[-\\frac{a}{2}, \\frac{a}{2}]$. After the collision, the particles are shifted back by the same amount.[@ihlekroll2001]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the MPCD Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Pseudo) Random Number Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the pillars of this thesis is the generation of random rotation angles for the rotation matrix needed in the collision step. This proved to be somewhat difficult. First, the standard algorithm of the C++ standard library was tried, but it didn't qualify because it performed poorly in comparison to the second and third algorithms tried, which are called \"Mersenne Twister\" and \"xoshiro256++\", respectively.[@wiki:mersennetwister][@cppreference:prng][@unimi:xoshiro]\n",
    "\n",
    "The Mersenne Twister was implemented using the C++ standard library. The xoshiro256++ was implemented using Sebastian Vigna's code with some additions.[@unimi:xoshiro]\n",
    "\n",
    "To compare algorithms, and also to make sure that the implementation of the xoshiro256++ is right, a $\\chi^2$ test for discrete observations was used. The generated angles in the interval $[0, 2\\pi)$ were split into $k+1$ buckets, where $k$ is the number of degrees of freedom of the $\\chi^2$ distribution. The test error\n",
    "\n",
    "\\begin{equation}\n",
    "T = \\sum_{b=1}^{k+1}{\\frac{(N_o - E[N_b])^2}{E[N_b]}},\n",
    "\\end{equation}\n",
    "\n",
    "where $E[N_b] = \\frac{N}{b}, b \\in \\{1, 2, \\dots , k+1\\}$ is the expected bucket size, is compared to $\\chi^2_{1-\\alpha, k}$, where $\\alpha$ is the signifigance level. The null hypothesis\n",
    "\n",
    "$$\n",
    "H_0: \\textrm{The angles are distributed uniformly in the interval } [0, 2 \\pi)\n",
    "$$\n",
    "\n",
    "is tested against the alternative hypothesis\n",
    "\n",
    "$$\n",
    "H_1: \\textrm{The angles are not distributed uniformly in the interval } [0, 2 \\pi) \\textrm{.}\n",
    "$$\n",
    "\n",
    "If the test should have significance level $\\alpha$, $H_0$ is rejected if $T \\ge \\chi^2_{1-\\alpha, k}$.[@fruehwirthstat][@wiki:chisquaredtest][@wiki:goodnessoffit]\n",
    "\n",
    "The results of the $\\chi^2$ test are summarised in [TODO: Table, and table formatting]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../x64/Debug/Data/RNG/\"\n",
    "mersenne = \"mersenne_twister_chi2.csv\"\n",
    "xoshiro = \"xoshiro_chi2.csv\"\n",
    "index = [\"k\", \"chi^2 probability\"]\n",
    "out_path = \"Generated/\"\n",
    "new_name = \"chi2_results_dirty.csv\"\n",
    "mersenne_twister_chi2 = pd.read_csv(path + mersenne).set_index(index)\n",
    "xoshiro256plusplus_chi2 = pd.read_csv(path + xoshiro).set_index(index)\n",
    "results = mersenne_twister_chi2.join(xoshiro256plusplus_chi2, on = index, how = \"inner\")\n",
    "results_csv = results.to_csv(out_path + new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{table}[]\n",
       "\\begin{tabular}{llll}\n",
       "\\rowcolor[HTML]{4472C4} \n",
       "{\\color[HTML]{FFF} \\textbf{k}} & {\\color[HTML]{FFF} \\textbf{chi\\textasciicircum{}2   probability}} & {\\color[HTML]{FFF} \\textbf{observed   MT}} & {\\color[HTML]{FFF} \\textbf{observed XS256++}} \\\\\n",
       "\\rowcolor[HTML]{D9E1F2} \n",
       "1                              & 5.991                                                             & 0.292                                      & 0.068                                         \\\\\n",
       "2                              & 7.815                                                             & 1.626                                      & 3.682                                         \\\\\n",
       "\\rowcolor[HTML]{D9E1F2} \n",
       "3                              & 9.488                                                             & 3.735                                      & 2.124                                         \\\\\n",
       "4                              & 11.07                                                             & 4.255                                      & 4.525                                         \\\\\n",
       "\\rowcolor[HTML]{D9E1F2} \n",
       "5                              & 12.592                                                            & 2.86                                       & 6.345                                         \\\\\n",
       "6                              & 14.067                                                            & 4.071                                      & 6.377                                         \\\\\n",
       "\\rowcolor[HTML]{D9E1F2} \n",
       "7                              & 15.507                                                            & 8.662                                      & 11.731                                        \\\\\n",
       "8                              & 16.919                                                            & 14.426                                     & 8.693                                         \\\\\n",
       "\\rowcolor[HTML]{D9E1F2} \n",
       "9                              & 18.307                                                            & 11.732                                     & 6.932                                         \\\\\n",
       "10                             & 19.675                                                            & 9.857                                      & 5.939                                         \\\\\n",
       "\\rowcolor[HTML]{D9E1F2} \n",
       "11                             & 21.026                                                            & 10.438                                     & 11.73                                         \\\\\n",
       "12                             & 22.362                                                            & 10.985                                     & 15.543                                        \\\\\n",
       "\\rowcolor[HTML]{D9E1F2} \n",
       "13                             & 23.685                                                            & 22.603                                     & 12.022                                        \\\\\n",
       "14                             & 24.996                                                            & 13.988                                     & 12.923                                        \\\\\n",
       "\\rowcolor[HTML]{D9E1F2} \n",
       "15                             & 26.296                                                            & 15.526                                     & 20.71                                         \\\\\n",
       "16                             & 27.587                                                            & 16.288                                     & 11.501                                        \\\\\n",
       "\\rowcolor[HTML]{D9E1F2} \n",
       "17                             & 28.869                                                            & \\cellcolor[HTML]{F8CBAD}32.26              & 12.478                                        \\\\\n",
       "18                             & 30.144                                                            & \\cellcolor[HTML]{F8CBAD}31.787             & 13.882                                       \n",
       "\\end{tabular}\n",
       "\\end{table}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\begin{table}[]\n",
    "\\begin{tabular}{llll}\n",
    "\\rowcolor[HTML]{4472C4} \n",
    "{\\color[HTML]{FFF} \\textbf{k}} & {\\color[HTML]{FFF} \\textbf{chi\\textasciicircum{}2   probability}} & {\\color[HTML]{FFF} \\textbf{observed   MT}} & {\\color[HTML]{FFF} \\textbf{observed XS256++}} \\\\\n",
    "\\rowcolor[HTML]{D9E1F2} \n",
    "1                              & 5.991                                                             & 0.292                                      & 0.068                                         \\\\\n",
    "2                              & 7.815                                                             & 1.626                                      & 3.682                                         \\\\\n",
    "\\rowcolor[HTML]{D9E1F2} \n",
    "3                              & 9.488                                                             & 3.735                                      & 2.124                                         \\\\\n",
    "4                              & 11.07                                                             & 4.255                                      & 4.525                                         \\\\\n",
    "\\rowcolor[HTML]{D9E1F2} \n",
    "5                              & 12.592                                                            & 2.86                                       & 6.345                                         \\\\\n",
    "6                              & 14.067                                                            & 4.071                                      & 6.377                                         \\\\\n",
    "\\rowcolor[HTML]{D9E1F2} \n",
    "7                              & 15.507                                                            & 8.662                                      & 11.731                                        \\\\\n",
    "8                              & 16.919                                                            & 14.426                                     & 8.693                                         \\\\\n",
    "\\rowcolor[HTML]{D9E1F2} \n",
    "9                              & 18.307                                                            & 11.732                                     & 6.932                                         \\\\\n",
    "10                             & 19.675                                                            & 9.857                                      & 5.939                                         \\\\\n",
    "\\rowcolor[HTML]{D9E1F2} \n",
    "11                             & 21.026                                                            & 10.438                                     & 11.73                                         \\\\\n",
    "12                             & 22.362                                                            & 10.985                                     & 15.543                                        \\\\\n",
    "\\rowcolor[HTML]{D9E1F2} \n",
    "13                             & 23.685                                                            & 22.603                                     & 12.022                                        \\\\\n",
    "14                             & 24.996                                                            & 13.988                                     & 12.923                                        \\\\\n",
    "\\rowcolor[HTML]{D9E1F2} \n",
    "15                             & 26.296                                                            & 15.526                                     & 20.71                                         \\\\\n",
    "16                             & 27.587                                                            & 16.288                                     & 11.501                                        \\\\\n",
    "\\rowcolor[HTML]{D9E1F2} \n",
    "17                             & 28.869                                                            & \\cellcolor[HTML]{F8CBAD}32.26              & 12.478                                        \\\\\n",
    "18                             & 30.144                                                            & \\cellcolor[HTML]{F8CBAD}31.787             & 13.882                                       \n",
    "\\end{tabular}\n",
    "\\end{table}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, both generators pass the $\\chi^2$ test and we do not have to reject our null hypothesis $H_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually, we can examine the generated buckets of both random generators in [TODO] the following plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mers = \"mersenne_\"\n",
    "xoshiro = \"xoshiro_\"\n",
    "csv = \".csv\"\n",
    "angle = \"alpha\"\n",
    "name_angles = \"angles\"\n",
    "\n",
    "mers_random_angle = pd.read_csv(path + mers + name_angles + csv)\n",
    "angle_mers = mers_random_angle[angle]\n",
    "xs_random_angle = pd.read_csv(path + xoshiro + name_angles + csv)\n",
    "angle_xs = xs_random_angle[angle]\n",
    "\n",
    "with sns.plotting_context(sns.set()):\n",
    "    x_size_per_plot = 7\n",
    "    y_size_per_plot = 4\n",
    "    rows = 4\n",
    "    cols = 2\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(x_size_per_plot * cols, y_size_per_plot * rows))\n",
    "    cols = [\"Mersenne Twister\", \"xoshiro256++\"]\n",
    "    for ax, col in zip(axes[0], cols):\n",
    "        ax.annotate(col, xy=(0.5, 1), xytext=(0, 10),\n",
    "                    textcoords='offset points', xycoords='axes fraction',\n",
    "                    size='24', ha='center', va='baseline')\n",
    "\n",
    "    axes[0,0].set_xlabel(\"5 buckets\")\n",
    "    axes[0,0].set_ylabel(\"frequency of angle\")\n",
    "    axes[0,0].hist(x=angle_mers,bins = 5)\n",
    "\n",
    "    axes[0,1].set_xlabel(\"5 buckets\")\n",
    "    axes[0,1].hist(x=angle_xs, bins = 5)\n",
    "\n",
    "    axes[1,0].set_xlabel(\"10 buckets\")\n",
    "    axes[1,0].set_ylabel(\"frequency of angle\")\n",
    "    axes[1,0].hist(x=angle_mers,bins = 10)\n",
    "\n",
    "    axes[1,1].set_xlabel(\"10 buckets\")\n",
    "    axes[1,1].hist(x=angle_xs, bins = 10)\n",
    "\n",
    "    axes[2,0].set_xlabel(\"50 buckets\")\n",
    "    axes[2,0].set_ylabel(\"frequency of angle\")\n",
    "    axes[2,0].hist(x=angle_mers,bins = 50)\n",
    "\n",
    "    axes[2,1].set_xlabel(\"50 buckets\")\n",
    "    axes[2,1].hist(x=angle_xs, bins = 50)\n",
    "\n",
    "    axes[3,0].set_xlabel(\"100 buckets\")\n",
    "    axes[3,0].set_ylabel(\"frequency of angle\")\n",
    "    axes[3,0].hist(x=angle_mers,bins = 100)\n",
    "\n",
    "    axes[3,1].set_xlabel(\"100 buckets\")\n",
    "    axes[3,1].hist(x=angle_xs, bins = 100)\n",
    "\n",
    "    plt.savefig(\"Assets/angle_buckets.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![A histogram of different bucket sizes generated by MT and xoshiro256++](Assets/angle_buckets.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mersenne Twister has been known to fail certain statistical tests since its inception, by virtue of its mathematical characteristics. There exist other algorithms that are designed to be faster and that do not fail any known statistical tests, examples of which are almost all of the algorithms in the xoshiro family.[@vigna2019] Ultimately, the xoshiro256++, developed by Sebastian Vigna and David Blackman, was used. It is a variant of the xorshift algorithm, which extends the bit-shift and xor methods by bitrotation, making it still very fast, and more \"random\" than the xorshift.[@wiki:xorshift][@unimi:xoshiro]\n",
    "\n",
    "Note that testing a (pseudo) random number generator is usually much more involved than this, but since this has already been done extensively by other authors, we are satisfied with the $\\chi^2$ test, simply to test the implementation of the xoshiro256++, since it plays an important part.[@wiki:prng][@vigna2019]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Particle Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The particle positions were drawn from a uniform real distribution in the interval $[0, 1)$ for the $x$-coordinate, and $[0, 1)$ for the $y$-coordinate. The velocities were initialized to be in the interval $[-1\\% \\cdot 1, 1\\% \\cdot 1)$ for the $v_x$ component, and $[-1\\% \\cdot 1, 1\\% \\cdot 1)$ for the $v_y$ component. The results can be seen in figure [TODO: figure numbering] below. From the positions in the first row, the velocities in the second row, particle streaming is applied for 1 and 10 timesteps, according to equation (TODO: equ numbering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../x64/Debug/Data/RNG/\"\n",
    "mers = \"mersenne_\"\n",
    "xoshiro = \"xoshiro_\"\n",
    "csv = \".csv\"\n",
    "particles = \"particles\"\n",
    "moved_xy = \"_after_move\"\n",
    "timesteps_moved_xy = \"_after_xx_timesteps\"\n",
    "x = \"x\"\n",
    "y = \"y\"\n",
    "vx = \"vx\"\n",
    "vy = \"vy\"\n",
    "\n",
    "mers_particles = pd.read_csv(path + mers + particles + csv)\n",
    "x_mers = mers_particles[x]\n",
    "y_mers = mers_particles[y]\n",
    "vx_mers = mers_particles[vx]\n",
    "vy_mers = mers_particles[vy]\n",
    "\n",
    "xs_particles = pd.read_csv(path + xoshiro + particles + csv)\n",
    "x_xs = xs_particles[x]\n",
    "y_xs = xs_particles[y]\n",
    "vx_xs = xs_particles[vx]\n",
    "vy_xs = xs_particles[vy]\n",
    "\n",
    "mers_moved_particles = pd.read_csv(path + mers + particles + moved_xy + csv)\n",
    "moved_x_mers = mers_moved_particles[x]\n",
    "moved_y_mers = mers_moved_particles[y]\n",
    "moved_vx_mers = mers_moved_particles[vx]\n",
    "moved_vy_mers = mers_moved_particles[vy]\n",
    "\n",
    "xs_moved_particles = pd.read_csv(path + xoshiro + particles + moved_xy + csv)\n",
    "moved_x_xs = xs_moved_particles[x]\n",
    "moved_y_xs = xs_moved_particles[y]\n",
    "moved_vx_xs = xs_moved_particles[vx]\n",
    "moved_vy_xs = xs_moved_particles[vy]\n",
    "\n",
    "mers_timesteps_moved_particles = pd.read_csv(path + mers + particles + timesteps_moved_xy + csv)\n",
    "timesteps_moved_x_mers = mers_timesteps_moved_particles[x]\n",
    "timesteps_moved_y_mers = mers_timesteps_moved_particles[y]\n",
    "timesteps_moved_vx_mers = mers_timesteps_moved_particles[vx]\n",
    "timesteps_moved_vy_mers = mers_timesteps_moved_particles[vy]\n",
    "\n",
    "xs_timesteps_moved_particles = pd.read_csv(path + xoshiro + particles + timesteps_moved_xy + csv)\n",
    "timesteps_moved_x_xs = xs_timesteps_moved_particles[x]\n",
    "timesteps_moved_y_xs = xs_timesteps_moved_particles[y]\n",
    "timesteps_moved_vx_xs = xs_timesteps_moved_particles[vx]\n",
    "timesteps_moved_vy_xs = xs_timesteps_moved_particles[vy]\n",
    "\n",
    "\n",
    "with sns.plotting_context(sns.set()):\n",
    "    point_size = 0.5\n",
    "    x_size_per_plot = 7\n",
    "    y_size_per_plot = 4\n",
    "    rows = 4\n",
    "    cols = 2\n",
    "    #plt.figure(num = 1, figsize=(x_size_per_plot * cols, y_size_per_plot * rows))\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=(x_size_per_plot * cols, y_size_per_plot * rows))\n",
    "    cols = [\"Mersenne Twister\", \"xoshiro256++\"]\n",
    "    for ax, col in zip(axes[0], cols):\n",
    "        ax.annotate(col, xy=(0.5, 1), xytext=(0, 10),\n",
    "                    textcoords='offset points', xycoords='axes fraction',\n",
    "                    size='24', ha='center', va='baseline')\n",
    "\n",
    "    axes[0,0].set_ylabel(y)\n",
    "    axes[0,0].plot(x_mers, y_mers, \"o\", markersize = point_size)\n",
    "    axes[0,0].set_xlabel(x)\n",
    "\n",
    "    axes[0,1].plot(x_xs, y_xs, \"o\", markersize = point_size)\n",
    "    axes[0,1].set_xlabel(x)\n",
    "\n",
    "    axes[1,0].set_ylabel(\"y-component of v\")\n",
    "    axes[1,0].plot(vx_mers, vy_mers, \"o\", markersize = point_size)\n",
    "    axes[1,0].set_xlabel(\"x-component of v\")\n",
    "\n",
    "    axes[1,1].plot(vx_xs, vy_xs, \"o\", markersize = point_size)\n",
    "    axes[1,1].set_xlabel(\"x-component of v\")\n",
    "\n",
    "    axes[2,0].set_ylabel(y)\n",
    "    axes[2,0].plot(moved_x_mers, moved_y_mers, \"o\", markersize = point_size)\n",
    "    axes[2,0].set_xlabel(x)\n",
    "\n",
    "    axes[2,1].plot(moved_x_xs, moved_y_xs, \"o\", markersize = point_size)\n",
    "    axes[2,1].set_xlabel(x)\n",
    "\n",
    "    axes[3,0].set_ylabel(y)\n",
    "    axes[3,0].plot(timesteps_moved_x_mers, timesteps_moved_y_mers, \"o\", markersize = point_size)\n",
    "    axes[3,0].set_xlabel(x)\n",
    "\n",
    "    axes[3,1].plot(timesteps_moved_x_xs, timesteps_moved_y_xs, \"o\", markersize = point_size)\n",
    "    axes[3,1].set_xlabel(x)\n",
    "\n",
    "    plt.savefig(\"Assets/particle_streaming.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Particle streaming without collision with MT and with xoshiro](Assets/particle_streaming.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the x and y coordinates are randomly initialized according to the shape of the container. Looking closely, one can see that our particles look very much like noise. The absolute value of the velocity components are initialized to at most 1% of their respective dimensions. After one timestep, some of the particles on the outer ranges have moved out of bounds, and after ten timesteps, the particles have thinned out considerably along the edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The collision step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the implementation of the collision step, a regular lattice, is needed. This grid has lattice constant $a$, where $a$ is a function of the desired average number of particles per cell, which is typically initialised to between three and 20[@winkl2009], although it can be as high as 70[@ihlekroll2001].\n",
    "\n",
    "The lattice constant $a$ is calculated as follows. The average number of particles per cell, $\\bar{N_c}$, is decided upon. If the grid has fixed dimensions, the number of cells is $n = \\frac{N}{\\bar{N_c}}$. This assumption is valid when only looking at flow through the region of interest and simulating continuous, neverending flow. Practically, this means ignoring particles that go too far out of this region of interest and creating particles that flow into it. If we assign a width $w$ and height $h$ to our region of interest, its area is $A = wh$. But since $n a^{2} = A$, this means that $a = \\sqrt{\\frac{wh}{n}}$. In figure (TODO), a visual representation of this setup can be seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../x64/Debug/Data/'\n",
    "csv = '.csv'\n",
    "name_frequencies = 'cell_frequencies_av_'\n",
    "row = 'i'\n",
    "col = 'j'\n",
    "num = 'n'\n",
    "name_constants = 'constants_'\n",
    "average_particles = 'average_particles_per_cell'\n",
    "\n",
    "\n",
    "import glob\n",
    "filenames_f = glob.glob('{}{}*{}'.format(path, name_frequencies, csv))\n",
    "filenames_c = glob.glob('{}{}*{}'.format(path, name_constants, csv))\n",
    "\n",
    "import pandas as pd\n",
    "pivots = []\n",
    "for path in filenames_f:\n",
    "    temp = pd.read_csv(path)\n",
    "    temp = temp[temp[row] != temp[row].max()]\n",
    "    temp = temp[temp[col] != temp[col].max()]\n",
    "    pivot = temp.pivot(index = row, columns = col, values = num)\n",
    "    pivots.append(pivot)\n",
    "    \n",
    "info_dfs = []    \n",
    "for path in filenames_c:\n",
    "    info_dfs.append(pd.read_csv(path))\n",
    "\n",
    "#for df in info_dfs:\n",
    "    #df[]\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize = (15,10))\n",
    "fig.tight_layout(pad=3.0)\n",
    "\n",
    "ax[0,0].set_title('Average: {}'.format(info_dfs[1][average_particles].values))\n",
    "sns.heatmap(pivots[1], ax = ax[0,0])#, ax=ax1)\n",
    "ax[0,1].set_title('Average: {}'.format(info_dfs[0][average_particles].values))\n",
    "sns.heatmap(pivots[0], ax = ax[0,1])#, ax=ax2)\n",
    "ax[1,0].set_title('Average: {}'.format(info_dfs[2][average_particles].values))\n",
    "sns.heatmap(pivots[2], ax = ax[1,0])\n",
    "ax[1,1].set_title('Average: {}'.format(info_dfs[3][average_particles].values))\n",
    "sns.heatmap(pivots[3], ax = ax[1,1])\n",
    "\n",
    "plt.savefig(\"Assets/average_grid_particles.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Average number of particles per Grid cell](Assets/average_grid_particles.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After particle streaming, a random shift is introduced. Its components are sampled from a uniform random distribution in the interval $[-\\frac{a}{2},\\frac{a}{2}]$. The random shift is the same for all particles, but usually differs from timestep to timestep. As discussed before, this step is necessary to restore the Galilean invariance that is violated when the molecular chaos assumption does not hold, which happens when simulating cold fluids or when using very small timesteps.[@ihlekroll2001]\n",
    "The shift is undone at the end of the collision step, after the velocity of a particle has been updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../x64/Debug/Data/\"\n",
    "csv = \".csv\"\n",
    "particles = \"particles_\"\n",
    "timestep = 'timestep_'\n",
    "x = 'x'\n",
    "y = 'y'\n",
    "vx = 'vx'\n",
    "vy = 'vy'\n",
    "\n",
    "import glob\n",
    "filenames = glob.glob('{}{}{}*.csv'.format(path, particles, timestep))\n",
    "\n",
    "import pandas as pd\n",
    "dfs = []\n",
    "for path in filenames:\n",
    "    df = pd.read_csv(path)\n",
    "    dfs.append(df)\n",
    "\n",
    "x_columns = ['{}{}'.format(x, num) for num in range(0, len(filenames))]\n",
    "y_columns = ['{}{}'.format(y, num) for num in range(0, len(filenames))]\n",
    "vx_columns = ['{}{}'.format(vx, num) for num in range(0, len(filenames))]\n",
    "vy_columns = ['{}{}'.format(vy, num) for num in range(0, len(filenames))]\n",
    "    \n",
    "x_evolution = pd.DataFrame(columns=x_columns)\n",
    "y_evolution = pd.DataFrame(columns=y_columns)\n",
    "vx_evolution = pd.DataFrame(columns=vx_columns)\n",
    "vy_evolution = pd.DataFrame(columns=vy_columns)\n",
    "\n",
    "i = 0\n",
    "for df in dfs:\n",
    "    x_evolution['{}{}'.format(x, i)] = df[x]\n",
    "    y_evolution['{}{}'.format(y, i)] = df[y]\n",
    "    vx_evolution['{}{}'.format(vx, i)] = df[vx]\n",
    "    vy_evolution['{}{}'.format(vy, i)] = df[vy]\n",
    "    i += 1\n",
    "\n",
    "x_evolution.head()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vx_evolution.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vy_evolution.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Velocity updating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The velocities of the particles update according to equation (TODO: numbering equ). To calculate the mean velocity $\\vec{V_{c}}$ of cell $c$, first a way to assign each particle a cell has to be established. Let the indices of the cell be $(i, j)$. The position of a cell can then be calculated as $x_c = j \\cdot a$ and $y_c = i \\cdot a$, where a is the lattice constant. This is implemented using the quite straightforward rule\n",
    "\n",
    "\\begin{equation}\n",
    "i = \\floor{\\frac{y}{a}}\\\\\n",
    "j = \\floor{\\frac{x}{a}},\n",
    "\\end{equation}\n",
    "where $(x,y)$ refers to the components of the particle's position vector. With this method to determine the cells, the total cell velocities and numbers of particles in each cell are calculated to obtain the mean cell velocity. Using a randomly sampled rotation angle \\alpha and rule (TODO: numbering equ), the particles' velocities are updated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing MPCD barebones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having implemented the essential features of the MPCD algorithm, it is time for testing it to make sure it was implemented correctly. This section will present conservation tests and visual tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../x64/Debug/Data/\"\n",
    "csv = \".csv\"\n",
    "particles = \"particles_\"\n",
    "timestep = 'timestep_'\n",
    "x = 'x'\n",
    "y = 'y'\n",
    "vx = 'vx'\n",
    "vy = 'vy'\n",
    "\n",
    "import glob\n",
    "filenames = glob.glob('{}{}{}*.csv'.format(path, particles, timestep))\n",
    "\n",
    "import pandas as pd\n",
    "dfs = []\n",
    "for path in filenames:\n",
    "    df = pd.read_csv(path)\n",
    "    dfs.append(df)\n",
    "\n",
    "x_columns = ['{}{}'.format(x, num) for num in range(0, len(filenames))]\n",
    "y_columns = ['{}{}'.format(y, num) for num in range(0, len(filenames))]\n",
    "vx_columns = ['{}{}'.format(vx, num) for num in range(0, len(filenames))]\n",
    "vy_columns = ['{}{}'.format(vy, num) for num in range(0, len(filenames))]\n",
    "    \n",
    "x_evolution = pd.DataFrame(columns=x_columns)\n",
    "y_evolution = pd.DataFrame(columns=y_columns)\n",
    "vx_evolution = pd.DataFrame(columns=vx_columns)\n",
    "vy_evolution = pd.DataFrame(columns=vy_columns)\n",
    "\n",
    "i = 0\n",
    "for df in dfs:\n",
    "    x_evolution['{}{}'.format(x, i)] = df[x]\n",
    "    y_evolution['{}{}'.format(y, i)] = df[y]\n",
    "    vx_evolution['{}{}'.format(vx, i)] = df[vx]\n",
    "    vy_evolution['{}{}'.format(vy, i)] = df[vy]\n",
    "    i += 1\n",
    "\n",
    "x_evolution.head()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vx_evolution.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vy_evolution.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The velocity of a particle updates according to\n",
    "\\begin{equation}\n",
    "\\vect{v_{i}} \\rightarrow \\vect{V_c} + \\matr{R}(\\alpha)[\\vect{v_i} - \\vect{V_c}],\n",
    "\\end{equation}\n",
    "\n",
    "where $\\vect{v_{i}}$ is the velocity of the $i-th$ particle, $\\vect{V_c}$ is the mean velocity of all particles belonging to cell $c$, specified by $i$'s position. The matrix\n",
    "\n",
    "$$\n",
    "R(\\alpha) = \n",
    "\\left[ \\begin{array}{rr}\n",
    "cos(\\alpha) & -sin(\\alpha) \\\\\n",
    "sin(\\alpha) & cos(\\alpha) \\\\\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "\n",
    "is a simple 2d-rotation matrix. The angle $\\alpha$ is uniformly sampled from the interval $[0, 2\\pi)$ on a per-cell basis.[@malev1999]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONSIDER THIS. SHOULD BECOME MAXWELL WHEN IMPLEMENTING COLLISION STEP TOO\n",
    "After having implemented the streaming step and that other one: after time driftting, looks like this: (+velocity distribution = maxwell?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some equations to copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "r(t + \\Delta t) = r(t) + \\Delta t \\cdot v(t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to Word doc (others possible too, f.ex. .tex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just do it manually, it works on anaconda env datascience\n",
    "\n",
    "import subprocess\n",
    "#automatic document conversion to markdown and then to word\n",
    "#first convert the ipython notebook paper.ipynb to markdown\n",
    "subprocess.run(\"jupyter nbconvert --to markdown thesis.ipynb --output-dir='./Generated'\") #--output-dir='./Generated'\n",
    "#next remove code\n",
    "path = \"./Generated/thesis.md\"\n",
    "with open(path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    idx = []\n",
    "    idx_files = []\n",
    "    for i, line in enumerate(lines):\n",
    "        if (line.startswith(\"```\")):\n",
    "            idx.append(i)\n",
    "        if (\"thesis_files\" in line):\n",
    "            c = line.find(\"thesis_files\")\n",
    "            lines[i] = line[0:c] + \"\" + line[c:]\n",
    "\n",
    "idx = sorted(idx, reverse=True) # reverse order so not deleting lines and then missing others\n",
    "for current, previous in zip(idx[::2], idx[1::2]):\n",
    "    print(\"Deleting {p}:{c}\".format(p=previous, c=current+1))\n",
    "    print('\\n'.join(lines[previous:current+1]))\n",
    "    del lines[previous:current+1]\n",
    "    \n",
    "with open(path, \"w\") as f:\n",
    "    #f.write(\"\\\\newcommand{\\matr}[1]\\\\textbf{#1}\")\n",
    "    #f.write(\"\\\\newcommand{\\\\vect}[1]{\\\\vec{#1}}\")\n",
    "    for line in lines:\n",
    "        f.write(\"%s\" % line)\n",
    "#next convert markdown to ms word\n",
    "conversion_tex = \"pandoc -s ./Generated/thesis.md -o ./Generated/thesis.tex --filter pandoc-citeproc --bibliography=\\\"list.bib\\\" --csl=\\\"apa.csl\\\"\"\n",
    "subprocess.run(conversion_tex)\n",
    "conversion_pdf = \"pandoc -s ./Generated/thesis.md -o ./Generated/thesis.pdf --filter pandoc-citeproc --bibliography=\\\"list.bib\\\" --csl=\\\"apa.csl\\\"\"\n",
    "subprocess.run(conversion_pdf)\n",
    "# LATEX TO DOCX pandoc -s math.tex -o example30.docx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equation Numbering jupyter extension\n",
    "conda install -c conda-forge jupyter_contrib_nbextensions\n",
    "\n",
    "jupyter contrib nbextension install --user\n",
    "\n",
    "jupyter nbextension enable equation-numbering/main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn equation numbering on/off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "MathJax.Hub.Config({\n",
    "    TeX: { equationNumbers: { autoNumber: \"AMS\" } }\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renumber equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "MathJax.Hub.Queue(\n",
    "  [\"resetEquationNumbers\", MathJax.InputJax.TeX],\n",
    "  [\"PreProcess\", MathJax.Hub],\n",
    "  [\"Reprocess\", MathJax.Hub]\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "datascience"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
