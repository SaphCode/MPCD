{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\newcommand{\\matr}[1]\\textbf{#1}\n",
       "\\newcommand{\\vect}[1]{\\vec{#1}}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\\newcommand{\\matr}[1]\\textbf{#1}\n",
    "\\newcommand{\\vect}[1]{\\vec{#1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_analysis = True\n",
    "with_obstacles = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = []\n",
    "I = []\n",
    "J = []\n",
    "U = []\n",
    "V = []\n",
    "pivot = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ../Data/constants_av10.csv does not exist: '../Data/constants_av10.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-8349ebff7c4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'constants_av'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mav\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mconstants\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mconstants\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mnum_timesteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconstants\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'timesteps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Software\\Anaconda\\envs\\datascience\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Software\\Anaconda\\envs\\datascience\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Software\\Anaconda\\envs\\datascience\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Software\\Anaconda\\envs\\datascience\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Software\\Anaconda\\envs\\datascience\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File ../Data/constants_av10.csv does not exist: '../Data/constants_av10.csv'"
     ]
    }
   ],
   "source": [
    "from math import floor\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import os.path\n",
    "\n",
    "path = \"Data/\"\n",
    "csv = \".csv\"\n",
    "av = 10\n",
    "constants = 'constants_av' + str(av) + csv\n",
    "\n",
    "constants = pd.read_csv(path + constants)\n",
    "num_timesteps = int(constants['timesteps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obstacles = None\n",
    "if (with_obstacles):\n",
    "    obstacles_path = path + 'constants_obstacles' + csv\n",
    "    obstacles_csv = pd.read_csv(obstacles_path)\n",
    "    obstacles = obstacles_csv[['x', 'y']]\n",
    "    obstacle_radius = float(obstacles_csv['r'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "shown_x = float(constants['width'])\n",
    "shown_y = float(constants['height'])\n",
    "\n",
    "saved = './Saved'\n",
    "saved_particles = '/particles.pkl'\n",
    "file_particles = saved + saved_particles\n",
    "\n",
    "def load_particles(path):\n",
    "    columns = []\n",
    "    x_columns = ['x{}'.format(it) for it in range(0, num_timesteps)]\n",
    "    vx_columns = ['vx{}'.format(it) for it in range(0, num_timesteps)]\n",
    "    y_columns = ['y{}'.format(it) for it in range(0, num_timesteps)]\n",
    "    vy_columns = ['vy{}'.format(it) for it in range(0, num_timesteps)]\n",
    "    columns.extend(x_columns)\n",
    "    columns.extend(y_columns)\n",
    "    columns.extend(vx_columns)\n",
    "    columns.extend(vy_columns)\n",
    "    particles = pd.DataFrame(columns = columns)\n",
    "\n",
    "    if (os.path.isfile(file_particles) and not new_analysis):\n",
    "        print('Found saved particles_x and particles_y files!')\n",
    "        particles = pd.read_pickle(file_particles)\n",
    "        print('Loaded particles files.')\n",
    "    else:\n",
    "        # Loading particles\n",
    "        print('Loading particles ..')\n",
    "        filenames_particles = glob.glob('{}*.csv'.format(path))\n",
    "        it = 0\n",
    "        for file in filenames_particles:\n",
    "            df = pd.read_csv(file)\n",
    "            particles[['x{}'.format(it), 'y{}'.format(it), 'vx{}'.format(it), 'vy{}'.format(it)]] = df[['x', 'y', 'vx', 'vy']]\n",
    "            it += 1\n",
    "            if (it % 10 == 0):\n",
    "                print('--loaded {}'.format(it))\n",
    "        particles.to_pickle(file_particles)\n",
    "        it = 0\n",
    "        print('Particles loaded and saved!\\n')\n",
    "        # Particles loaded\n",
    "    return particles\n",
    "\n",
    "\n",
    "particles_path = '{parent}particles_av{av}'.format(parent = path, av=av)    \n",
    "particles = load_particles(path = particles_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_dim = float(constants['cell_dim'])\n",
    "width = float(constants['width'])\n",
    "height = float(constants['height'])\n",
    "shown_cols = floor(width / cell_dim)\n",
    "shown_rows = floor(height / cell_dim)\n",
    "\n",
    "saved = './Saved'\n",
    "saved_cells = '/cells.pkl'\n",
    "file_cells = saved + saved_cells\n",
    "\n",
    "columns = ['i', 'j', 'meanX', 'meanY', 'num']\n",
    "\n",
    "def load_cells(path, columns, shown_rows, shown_cols):\n",
    "    \n",
    "    index = ['t']\n",
    "    if (os.path.isfile(file_cells)):\n",
    "        cells = pd.read_pickle(file_cells)\n",
    "        #print(cells)\n",
    "        #cells.set_index(index, inplace=True)\n",
    "    else:\n",
    "        # Loading cells\n",
    "        print('Loading cells')\n",
    "        \n",
    "        cells_timesteps = []\n",
    "        \n",
    "        it = 0\n",
    "        filenames_cells = glob.glob('{}*.csv'.format(path))\n",
    "        for file in filenames_cells:\n",
    "            df = pd.read_csv(file)\n",
    "            cells_timesteps.append(df)\n",
    "            #df[[i,j]] = (df[[i,j]] + 1/2) * cell_dim\n",
    "            #print(df.head())\n",
    "            it += 1\n",
    "            if (it % 10 == 0):\n",
    "                print('--loaded {}'.format(it))\n",
    "        #cells.to_pickle(file_cells)\n",
    "        print('Cells loaded and saved!\\n')\n",
    "        # Cells loaded\n",
    "        return cells_timesteps\n",
    "    \n",
    "def prepare_cells(cells_timesteps, columns, shown_rows, shown_cols):\n",
    "    # Preparing cell values\n",
    "    print('Preparing cell values ..')\n",
    "\n",
    "    array_i = np.arange(0, shown_rows)\n",
    "    array_j = np.arange(0, shown_cols)\n",
    "    I,J = np.meshgrid(array_j, array_i)\n",
    "\n",
    "    U = []\n",
    "    V = []\n",
    "\n",
    "    i = columns[0]\n",
    "    j = columns[1]\n",
    "    vx = columns[2]\n",
    "    vy = columns[3]\n",
    "    num = columns[4]\n",
    "\n",
    "    pivots = []\n",
    "    for df in cells_timesteps:\n",
    "        # only the rows and cols above 0\n",
    "        # and below shown_rows, shown_cols\n",
    "        # this is to \n",
    "        # --1. no vaccuum around simulated region\n",
    "        # --2. I,J are fixed size\n",
    "        U_inner = []\n",
    "        V_inner = []\n",
    "        for it in array_i: # TODO: check this code something seems foul (row, cols, but only using rows)\n",
    "            temp = df.loc[df[i] == it]\n",
    "            u = np.array(temp[vx])\n",
    "            U_inner.append(u)\n",
    "            v = np.array(temp[vy])\n",
    "            V_inner.append(v)\n",
    "        U.append(np.array(U_inner))#, dtype = object))\n",
    "        V.append(np.array(V_inner))#, dtype = object))\n",
    "\n",
    "        pivot = df.pivot(index = i, columns = j, values = num)\n",
    "        pivots.append(pivot)\n",
    "\n",
    "    print('Cell preparation complete!')\n",
    "    return I,J,U,V, pivots\n",
    "    # Cell preparation complete\n",
    "\n",
    "\n",
    "cells_path = path + 'cells_av{}'.format(av)\n",
    "cells_timesteps = load_cells(cells_path, columns, shown_rows, shown_cols)\n",
    "I,J,U,V,pivots = prepare_cells(cells_timesteps, columns, shown_rows, shown_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting\n",
    "#with (sns.plotting_context(sns.set())):\n",
    "x_0_region = 0\n",
    "x_max_region = int(constants['width'])\n",
    "y_0_region = 0\n",
    "y_max_region = int(constants['height'])\n",
    "\n",
    "streamplot_density = [0.5, 1]\n",
    "\n",
    "print('Plotting data ..')\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "ax = [fig.add_subplot(2,2,i+1) for i in range(4)]\n",
    "\n",
    "for a in ax:\n",
    "    a.set_xticklabels([])\n",
    "    a.set_yticklabels([])\n",
    "    #a.set_aspect('equal')\n",
    "    \n",
    "fig.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "color = np.sqrt(U[0]**2 + V[0]**2)\n",
    "point_size = 0.3\n",
    "\n",
    "#circles = []\n",
    "if with_obstacles:\n",
    "    for index, o in obstacles.iterrows():\n",
    "        circle1 = plt.Circle((o['x'], o['y']), obstacle_radius, color = 'gray')\n",
    "        circle2 = plt.Circle((o['x'], o['y']), obstacle_radius, color = 'gray')\n",
    "        #circle3 = plt.Circle((o['x'], o['y']), obstacle_radius, color = 'black')\n",
    "        #circles.append(circle)\n",
    "        ax[1].add_artist(circle1)\n",
    "        ax[2].add_artist(circle2)\n",
    "        #ax[3].add_artist(circle3)\n",
    "        #ax[0].xaxis.set_ticks([])\n",
    "#ax[0].yaxis.set_ticks([])\n",
    "ax[0].quiver(I, J, U[0], V[0], color)\n",
    "ax[0].set(xlim=(x_0_region-1,x_max_region), ylim=(y_0_region-1,y_max_region))\n",
    "\n",
    "#ax[1].xaxis.set_ticks([])\n",
    "#ax[1].yaxis.set_ticks([])\n",
    "ax[1].streamplot(I, J, U[0], V[0], color=color, density = streamplot_density) # grid\n",
    "ax[1].set(xlim=(x_0_region-1,x_max_region), ylim=(y_0_region-1,y_max_region))\n",
    "\n",
    "#ax[2].xaxis.set_ticks([])\n",
    "#ax[2].yaxis.set_ticks([])\n",
    "ax[2].plot(particles['x0'], particles['y0'], \"o\", markersize = point_size)\n",
    "if with_obstacles:\n",
    "    sns.scatterplot(ax = ax[2], x = obstacles['x'], y = obstacles['y'], s = obstacle_radius)\n",
    "ax[2].set(xlim=(x_0_region, x_max_region), ylim=(y_0_region,y_max_region))\n",
    "\n",
    "#ax[3].xaxis.set_ticks([])\n",
    "#ax[3].yaxis.set_ticks([])\n",
    "#img = ax[3].imshow(pivot, cmap='hot')\n",
    "#fig.colorbar(img, ax=ax[3], fraction=0.046, pad=0.005)\n",
    "sns.heatmap(pivots[0], ax=ax[3], xticklabels = False, yticklabels = False, cbar_kws={\"fraction\": 0.046, \"pad\": 0.01})\n",
    "ax[3].set(xlim=(x_0_region-1,x_max_region), ylim=(y_0_region,y_max_region))\n",
    "#ax[3].xticks('')\n",
    "#ax[3].yticks('')\n",
    "ax[3].set_ylabel('')\n",
    "ax[3].set_xlabel('')\n",
    "#ax[1,1].imshow(pivot, cmap='hot')\n",
    "\n",
    "plt.savefig(\"Assets/initial_region.png\")\n",
    "#plt.close()\n",
    "print('Data plotted and saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Plotting data ..')\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "ax = [fig.add_subplot(2,2,i+1) for i in range(4)]\n",
    "\n",
    "timesteps = int(constants['timesteps']) - 1\n",
    "\n",
    "for a in ax:\n",
    "    a.set_xticklabels([])\n",
    "    a.set_yticklabels([])\n",
    "    #a.set_aspect('equal')\n",
    "    \n",
    "fig.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "color = np.sqrt(U[timesteps]**2 + V[timesteps]**2)\n",
    "point_size = 0.3\n",
    "\n",
    "if with_obstacles:\n",
    "    for index, o in obstacles.iterrows():\n",
    "        circle1 = plt.Circle((o['x'], o['y']), obstacle_radius, color = 'orange')\n",
    "        circle2 = plt.Circle((o['x'], o['y']), obstacle_radius, color = 'orange')\n",
    "        #circle3 = plt.Circle((o['x'], o['y']), obstacle_radius, color = 'black')\n",
    "        #circles.append(circle)\n",
    "        ax[1].add_artist(circle1)\n",
    "        ax[2].add_artist(circle2)\n",
    "        #ax[3].add_artist(circle3)\n",
    "        #ax[0].xaxis.set_ticks([])\n",
    "\n",
    "ax[0].xaxis.set_ticks([])\n",
    "ax[0].yaxis.set_ticks([])\n",
    "ax[0].quiver(I, J, U[timesteps], V[timesteps], color)\n",
    "ax[0].set(xlim=(x_0_region-1,x_max_region), ylim=(y_0_region-1,y_max_region))\n",
    "\n",
    "ax[1].xaxis.set_ticks([])\n",
    "ax[1].yaxis.set_ticks([])\n",
    "ax[1].streamplot(I, J, U[timesteps], V[timesteps], color=color, density=streamplot_density) # grid\n",
    "ax[1].set(xlim=(x_0_region-1,x_max_region), ylim=(y_0_region-1,y_max_region))\n",
    "\n",
    "ax[2].xaxis.set_ticks([])\n",
    "ax[2].yaxis.set_ticks([])\n",
    "ax[2].plot(particles['x{}'.format(timesteps)], particles['y{}'.format(timesteps)], \"o\", markersize = point_size)\n",
    "ax[2].set(xlim=(x_0_region,x_max_region), ylim=(y_0_region,y_max_region))\n",
    "\n",
    "ax[3].xaxis.set_ticks([])\n",
    "ax[3].yaxis.set_ticks([])\n",
    "#img = ax[3].imshow(pivot, cmap='hot')\n",
    "#fig.colorbar(img, ax=ax[3], fraction=0.046, pad=0.005)\n",
    "sns.heatmap(pivots[timesteps], ax=ax[3], xticklabels = False, yticklabels = False, cbar_kws={\"fraction\": 0.046, \"pad\": 0.005})\n",
    "ax[3].set(xlim=(x_0_region,x_max_region), ylim=(y_0_region,y_max_region))\n",
    "#ax[3].xticks('')\n",
    "#ax[3].yticks('')\n",
    "ax[3].set_ylabel('')\n",
    "ax[3].set_xlabel('')\n",
    "#ax[1,1].imshow(pivot, cmap='hot')\n",
    "\n",
    "plt.savefig(\"Assets/stationary_region.png\")\n",
    "#plt.close()\n",
    "print('Data plotted and saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. C:/Users/chris/OneDrive/Documents/Studium/Studieng√§nge/Bachelor%20Physik/Bachelorarbeit/Cell-level%20canonical%20sampling%20by%20velocity%20scaling%20for%20multiparticlecollision%20dynamics%20simulations.pdf formula (2), $t+\\Delta t$ The velocity scaling might not be right because of this mistake?\n",
    "2. Add virtual particles where the obstacles are. Done\n",
    "3. Clean code. It's hardly readable. Half done\n",
    "4. Maybe remove the shared pointers, theyre stupid actually.\n",
    "5. For \\_obstacles, you can actually do it. (make unique f.ex? or just use two vectors for wall and obstacles) They only appear in pipe and simulation, but particles need to stay in simulation, and particles need obstacles to check if they are in bounds initially.\n",
    "6. For interactors too. (also pipe)\n",
    "8. Search for TODO\n",
    "9. check velocity for before and after thermostat/ maybe adjust temperature?\n",
    "10. at() of map now throws. this should be in grid or smth. fix it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiparticle collision dynamics (MPCD), also known as Stochastic Rotation Dynamics (SRD)[@winkl2009] is a technique originally introduced to study the dynamics of complex fluids such as polymers in solution. Besides MPCD, there exist other mesoscopic models that have been constructed for this purpose, such as Langevin, Direct Simulation Monte Carlo and lattice Boltzmann methods.[@malev1999] We only concern ourselves with the application of MPCD, it follows that any comparison between methods are out of the scope of this thesis.\n",
    "\n",
    "The MPCD technique models the fluid using particles, their positions and velocities are treated as continuous variables. The system is divided up into cells that have no restriction on the number of particles, each of the cells is part of a regular lattice. The dynamics is split into two parts: Particle streaming and multiparticle collision dynamics. Particle streaming is treated exactly for each particle in the system, while the collision step is approximated on a cell level. The multiparticle collision dynamics conserves mass, momentum and energy and leads to the correct hydrodynamical equations.[@malev1999] The streaming and collision step are described in more detail in (TODO: section numbering)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The MPCD algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The system we are modelling consists of $N$ particles with mass $m$, continuous position $\\vec{r_{i}}$ and velocity $\\vec{v_{i}}$, where $i \\in \\{1, 2, \\dots, N\\}$. One timestep $\\Delta t$ shall correspond to having calculated all the new particle positions and velocities in the streaming and collision steps, respectively. For each of the $N$ particles, the streaming and collision steps are applied, and this pattern is repeated until the wanted number of timesteps have elapsed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The streaming step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The streaming step is very straightforward. The particle positions are simply updated according to\n",
    "\n",
    "\\begin{equation}\n",
    "\\vect{r_{i}} \\rightarrow \\vect{r_{i}} + \\Delta t \\cdot \\vect{v_{i}}\\textrm{,}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\Delta t$ is a small time interval.[@winkl2009][@malev1999]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The collision step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collision step is somewhat more complicated. It involves the mean velocity of all particles in a particular cell, $\\vect{V_c}$, the velocity of the particle $i$, $\\vec{v_i}$, and a rotation matrix $\\matr{R}(\\alpha)$. The vector $\\vect{v_i}$ is rotated relative to the mean velocity $\\vect{V_c}$ of all particles in cell $c$, cell $c$ being the cell which particle $i$ belongs to. It is shown in [@malev1999] that the rule,\n",
    "\n",
    "\\begin{equation}\n",
    "\\vect{v_i} \\rightarrow \\vect{V_c} + \\matr{R}(\\alpha) [\\vect{v_i} - \\vect{V_c}] \\textrm{,}\n",
    "\\end{equation}\n",
    "\n",
    "conserves mass, momentum and energy under the molecular chaos assumption[@malev1999][@winkl2009, molecular chaos, p.7]. The rotation matrix $\\matr{R}(\\alpha)$ is a simple 2d rotation matrix\n",
    "\n",
    "\\begin{equation}\n",
    "R(\\alpha) = \n",
    "\\left[ \\begin{array}{rr}\n",
    "cos(\\alpha) & -sin(\\alpha) \\\\\n",
    "sin(\\alpha) & cos(\\alpha) \\\\\n",
    "\\end{array}\\right],\n",
    "\\end{equation}\n",
    "\n",
    "where $\\alpha$ is sampled on a per-cell basis from the interval $[0, 2\\pi)$ with a uniform distribution. Furthermore, for each particle in the cell $\\alpha$ flips its sign with probability $\\frac{1}{2}$.[@winkl2009, (p.6)]\n",
    "The mean velocity of a cell is defined as\n",
    "\n",
    "\\begin{equation}\n",
    "\\vect{V_c} = \\frac{1}{N_c} \\sum_{i=1}^{N_c} \\vect{v_i} \\textrm{,}\n",
    "\\end{equation}\n",
    "\n",
    "where $N_c$ is the number of particles in cell c.[@malev1999]\n",
    "\n",
    "The original MPCD algorithm was not Galilean invariant. The problem lay in the \"molecular chaos\" assumption, which means that particles involved in a collision have no memory of earlier encounters when colliding. This assumption is problematic when the mean free path \n",
    "\n",
    "\\begin{equation}\n",
    "\\lambda = \\Delta t \\sqrt{\\frac{k_{B}T}{m}}\n",
    "\\end{equation}\n",
    "\n",
    "is small compared to the cell size $a$, since the same particles collide with each other repeatedly and thus build up correlations. When $\\lambda \\gg a$ Ihle and Kroll have shown that the molecular chaos assumption holds and the simulated results deviate from experimental ones only negligibly.[@ihlekroll2001, p.2][@winkl2009]\n",
    "\n",
    "The solution to this problem is to shift all particles by the same random vector $s$ before the collision step. The components of $s$ are sampled randomly from a uniform distribution in the interval $[-\\frac{a}{2}, \\frac{a}{2}]$. After the collision, the particles are shifted back by the same amount.[@ihlekroll2001]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additions to the original MPCD Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction of fluid particles with obstacles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fluid flows through a pipe that will be setup somewhere between 100 to 400 width, and 20 - 50 height, as can be seen in figure (TODO: figure number). In SI units, we might imagine .. (TODO: expand this section). The pipe has two parallel walls, the fluid-wall interaction is modeled using stick (or no-slip) boundary conditions. (TODO: figure). When a particle hits the wall, it goes back the same way it came there, which means that the sign of the velocity vector is flipped. Stick boundary conditions are shown in figure. (TODO: figure numbering) The fluid interacts with obstacles, which are modeled exactly like the wall, with a small complication from the geometry. To simplify this problem, the approximate collision process found in [@nikoubashman2013] is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Container of MPCD fluid, with obstacles](Release/Assets/MPCD_Pipe.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Reflection of particle from wall, no slip boundary conditions](Release/Assets/Wall_noslip_boundary_conditions_reflection.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the shifting of the grid before the collision step, the cells next to the walls might be partially blocked by the wall. This partial blocking by the wall causes the cell to have, on average, less particles than it would have, had the grid not been shifted. The change in average particles distorts the collision step of particles near the wall. For more complex geometries than the one used in this thesis, the wall wont even be parallel to the grid lines, which makes this a problem even without a grid shift. To compensate this, it has been shown in (TODO: find a source) that the following process undoes the distortion.\n",
    "\n",
    "As is shown in figure (TODO: figure numbering), imagine a cell being blocked a little bit by the wall. Let's assume that the average number of particles per cell is 4. In the first cell, we count 3 particles. What is now done, is to introduce a \"virtual\" particle, which we might imagine as being behind the wall, though the position of it does not matter. Jumping to the second cell, we introduce 2 \"virtual particles\". In general, $\\bar N_c - N_c$ particles are introduced, where $\\bar N_c$ is the average number of particles per cell, chosen to be an integer, and $N_c$ is the actual number of particles found in cell $c$. Their velocities are sampled from two independent normal distributions with mean $\\mu = 0$ and variation $\\sigma^2 = \\frac{k_{B}T}{m}$, where $k_{B}$ is the boltzmann constant, $T$ is the temperature of the fluid, and $m$ is the mass of one particle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Undoing the distortion caused by the grid shift](Release/Assets/Wall_stick_boundary_conditions_virtual_particles.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ballistics step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ballistics step might be called a substep of particle streaming. After the particles are moved, their position is checked for interaction with the wall or obstacles. If particles overshoot the bounds set by either the wall or obstacles, their position is set to the collision point, their velocity is reversed, subsequently they are moved for the rest of the distance they would have travelled, as explained in section. (TODO: section numbering) This means we are assuming elastic collision between the particles, the walls and obstacles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant Force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several methods exist to model poseuille flow.[@nikoubashman2013] Here, a gravitational approach is chosen. This means an external force acts on the unit volume of the fluid, which is given by,\n",
    "\n",
    "\\begin{equation}\n",
    "\\vect{F} = \\rho_S g \\hat x,\n",
    "\\end{equation}\n",
    "\n",
    "where $\\rho_S$ is the mass density of the solvent, $g$ is the acceleration constant and $\\hat x$ is the unit vector in the $x$-direction. This force is incorporated into the simulation by updating the position and velocity of a particle according to the solution for constant force Newton's equations.[@nikoubashman2013]\n",
    "\n",
    "Because now a force acts on the particles, as seen in figure (TODO figure#), additional energy is coming into the system which needs to be controlled. The tool to do this in MPCD is called a thermostat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constant force in combination with no-slip boundary conditions applied by the bounce-back rule leads to a parabolic velocity profile\n",
    "\n",
    "\\begin{equation}\n",
    "v_x(y) = \\frac{4 v_{max} (D - y) y}{D^2},\n",
    "\\end{equation}\n",
    "\n",
    "where $D$ is the distance between walls. The maximum velocity of this profile is given by\n",
    "\n",
    "\\begin{equation}\n",
    "v_{max} = \\frac{m N_c g D^2}{8 \\eta},[@huang2010]\n",
    "\\end{equation}\n",
    "\n",
    "where $\\eta$ refers to the viscosity of the fluid.\n",
    "The profile obtained from the simulation is plotted against the expected profile in figure (TODO: figure #)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viscosity(v_max, m = 1, av_N_c = 10, g = 0.01, D = 20):\n",
    "    return (m * av_N_c * g * D**2) / (8 * v_max)\n",
    "\n",
    "def parabolic_flow(y, v_max = 4, D = 20):\n",
    "    return (4 * v_max * (D - y) * y)/(D**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.linspace(0, 20, 100)\n",
    "plt.plot(y, parabolic_flow(y))\n",
    "plt.title('Parabolic flow')\n",
    "\n",
    "rowsums = [row.sum()/len(row) for row in U[timesteps]]\n",
    "plt.plot(range(len(rowsums)), rowsums, \"o-\")\n",
    "plt.xlabel('x-Velocity')\n",
    "plt.ylabel('Cell number')\n",
    "plt.title('Velocity profile, averaged over all rows, for the last timestep ({})'.format(timesteps))\n",
    "plt.savefig(\"Assets/velocity_profile.png\")\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thermostat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To counteract the heating up of the fluid by the constant force on every particle, a thermostat is needed. As described in Winkler[@winkl2009], the cell-level thermostat was used. For this, we need to sample a kinetic energy from the gamma distribution\n",
    "\n",
    "\\begin{equation}\n",
    "P(E_k) = \\frac{q}{E_k\\Gamma(f/2)}\\left(\\frac{E_k}{k_BT}\\right)^{f/2} e^{-\\frac{E_k}{k_B T}},\n",
    "\\end{equation}\n",
    "\n",
    "where $f = 2 (N_c - 1)$ are the degrees of freedom of the system. The velocities (TODO: which velocities? I scaled the $\\Delta v_i$ and the $v_i$, and both gave the same effect) are then scaled by the factor \n",
    "\n",
    "\\begin{equation}\n",
    "\\kappa = \\left(\\frac{2E_k}{\\sum_{i=1}^{N_c}m\\Delta v_i^2}\\right)^{1/2},\n",
    "\\end{equation}\n",
    "\n",
    "where $\\Delta v_i = v_i - V_c$. The effect of the thermostat can be seen in figure (TODO: figure#), in which the theoretical distribution[@winkl2009]\n",
    "\n",
    "\\begin{equation}\n",
    "P(\\Delta v) = \\sum_{N_c = 2}^{\\infty} e^{-\\bar{N_c}} \\frac{\\bar{N_c}^{N_c}}{N_c!} \\frac{P(\\Delta v, N_c)} { \\left( 1 - (\\bar{N_c} + 1) \\cdot e^{-\\bar{N_c}} \\right)},\n",
    "\\end{equation}\n",
    "where \n",
    "\n",
    "\\begin{equation}\n",
    "P(\\Delta v, N_c) = \\left(\\frac{m}{2 \\pi k_B T (1 - 1/N_c)}\\right)^{3/2} exp\\left(-\\frac{m}{2 k_B T (1 - 1/N_c)} \\Delta v^2 \\right),\n",
    "\\end{equation}\n",
    "\n",
    "is plotted against the distribution of $|\\Delta v|$ in a collision cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def theoretical_dist(Delta_v, N_c, av_N_c = 10, m = 1, k_B = 1, T = 1):\n",
    "    A = (m/(2 * math.pi * k_B * T * (1 - 1/N_c)))**(3/2)\n",
    "    B = np.exp(-(m/(2 * k_B * T * (1 - 1/N_c))) * Delta_v**2)\n",
    "    return A * B\n",
    "\n",
    "def poisson_avg(Delta_v, max_sum = 1000, av_N_c = 10, m = 1, k_B = 1, T = 1):\n",
    "    e = math.exp(-av_N_c)\n",
    "    total = 0\n",
    "    for N_c in range(2, max_sum):\n",
    "        P = (av_N_c**N_c)/(math.factorial(N_c))\n",
    "        N = theoretical_dist(Delta_v, N_c, m, k_B, T)\n",
    "        total += P * (N)\n",
    "    D = 1 - (av_N_c + 1) * e\n",
    "    return e * total/D\n",
    "\n",
    "def plot_theoretical():\n",
    "    Delta_v = np.linspace(0, 4, 1000)\n",
    "    plt.plot(Delta_v, poisson_avg(Delta_v))\n",
    "    plt.show()\n",
    "    \n",
    "plot_theoretical()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collision with circular obstacles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collision rules are detailed in figure (TODO: figure#). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Collision with circular obstacle](Assets/MPCD_obstacle_collision_rule.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the particle\\'s position before the streaming step \\vect{p_0}, to the particle\\'s position after moving, \\vect{p_1}, a line with equation\n",
    "\n",
    "\\begin{equation}\n",
    "(y - y_0) = k (x - x_0),\n",
    "\\end{equation}\n",
    "\n",
    "where $k = \\frac{y_1 - y_0}{x_1 - x_0}$ is drawn. This line intersects with a circle with equation\n",
    "\n",
    "\\begin{equation}\n",
    "(x - x_c)^2 + (y - y_c)^2 = r^2,\n",
    "\\end{equation}\n",
    "\n",
    "where $(x_c, y_c)$ is the center position of the circle. By solving the equation, we get 2 collision points, the rule for choosing the right one is then to take the one that's on the direct path from the new position to the old. We calculate the quantity by which the particle has \"overshot\" the collision point, and correct its position to $\\vect{p_{correct}} = \\vect{p_1} - 2 \\vect{o},$ where $\\vect{o}$ is the amount which the particle has gone too far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the MPCD Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Number Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling from a normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To initialize the velocities of generated particles, a Maxwell-Boltzmann distribution must be used. In two this is equivalent to the product of two independent normal distributions with mean $\\mu = 0$ and variance $\\sigma^2 = \\frac{k_{B}T}{m}$, where $k_{B}$ is the boltzmann constant, $T$ is the temperature of the fluid, and $m$ is the mass of one particle. Thus, the velocities are sampled from normal distributions.[@wiki:maxwell_boltzmann]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this purpose, the normal distribution of the C++ standard library was used, along with a Mersenne Twister number generator, which, although it has some shortcomings, will for all practical purposes suffice for the scope of this thesis. Although the Xoshiro is far superior to the Mersenne Twister algorithm[@vigna2019], to adapt it for this purpose did not seem worth the effort, because the difference in quality will not be visible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MPCD barebones algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The streaming step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_This section was shortened, since I think it does not deserve its own._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The streaming step was implemented and tested in an older version of this thesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The collision step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To model the interaction of particles with each other, we implement the collision rules, as detailed in section (TODO: section numbering). To avoid some of the downfalls of the original algorithm, as detailed in section (TODO: section#), we implement a grid shift."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid shift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After particle streaming, the grid is shifted. The components of this shift, $\\vect s$ are sampled from a uniform random distribution in the interval $[-\\frac{a}{2},\\frac{a}{2}]$. This step is necessary to restore Galilean invariance, which is violated when the molecular chaos assumption does not hold. This happens when simulating cold fluids or when using very small timesteps.[@ihlekroll2001]\n",
    "The shift is undone at the end of the collision step, after the velocity of all particles has been updated.\n",
    "\n",
    "If particles go out of the simulation bounds due to the grid shift, they reappear at the other end as described in section (TODO: section numbering). Because the wall will not align with the grid anymore, virtual particles as described in section (TODO: section numbering) have to be introduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Velocity updating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_TODO_\n",
    "_Note: The floor is not rendering correctly at the moment, but it's a mistake that will be fixed in the final version._\n",
    "\n",
    "The velocities of the particles update according to equation (TODO: numbering equ). To calculate the mean velocity $\\vec{V_{c}}$ of cell $c$, first a way to assign each particle a cell has to be established. Let the indices of the cell be $(i, j)$. The position of a cell can then be calculated as $x_c = j \\cdot a + s_x$ and $y_c = i \\cdot a + s_y$, where $a$ is the lattice constant, $s_x$ and $s_y$ are the $x$ and $y$ components of grid shift $\\vect s$. So for the indices it follows,\n",
    "\n",
    "\\begin{equation}\n",
    "i = floor{\\frac{y - s_y}{a}}\\\\\n",
    "j = floor{\\frac{x - s_x}{a}},\n",
    "\\end{equation}\n",
    "where $(x,y)$ refers to the components of the particle's position vector. With this method to determine the cells, the total cell velocities and numbers of particles in each cell are calculated to obtain the mean cell velocity. Using a uniform randomly sampled rotation angle $\\alpha$ and rule (TODO: numbering equ), the particles' velocities are updated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing MPCD barebones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having implemented the essential features of the MPCD algorithm, namely the streaming and collision steps, it is time for testing it to make sure it was implemented correctly. This section will present conservation tests and visual tests. Note that there are no walls and no obstacles, no forces and no thermostat, yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timestep animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To inspect and understand the behavior of our simulation, an animation was created. The fluid starts out in a random state, which means that the positions and velocities of the particles are initialized randomly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial state, and the one after 100 timesteps, of region $x \\in (200, 240)$, $y \\in (0, 20)$ can be seen below (TODO figure#). \n",
    "\n",
    "__An explanation of the plots__: Top left is a quiver plot, where I plot the velocity vectors of cells at their position. Top right is streamplot, where this same data is used to visualize streaming, background work (interpolation, probably) done by python. Bottom left are the particles positions in a 2d plane. Bottom right is a heatmap of number of particles per cell (will be helpful when implementing walls, because it should be less there if we don't implement virtual particles)\n",
    "\n",
    "_The animations were sent by mail. If you did not get them and would like to see them, you can access them here: https://www.dropbox.com/sh/ih11zkpzapvd7qm/AADgbdW_ejXumRROJbCgMxaUa?dl=0_\n",
    "\n",
    "_The animations will probably be more interesting once force, thermostat & obstacles have been implemented, but it was a good way to check the behavior of the simulation against the intuition._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Initial State of region with barebones MPCD implementation](Assets/initial_region.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Ending (maybe stationary) state of region with barebones MPCD implementation](Assets/stationary_region.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Ending velocity profile](Release/Assets/velocity_profile.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histograms velocity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for animation of histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "\n",
    "def update_hist(num, data):\n",
    "    if (num % 10 == 0):\n",
    "        print('Frame: {}'.format(num))\n",
    "    plt.cla()\n",
    "    plt.hist(data[num], bins = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_velocities = [particles['vx{}'.format(i)] for i in range(timesteps)]\n",
    "\n",
    "n_frames = num_timesteps - 1\n",
    "\n",
    "fig = plt.figure()\n",
    "x_velocities_hist = plt.hist(x_velocities[0])\n",
    "\n",
    "anim = animation.FuncAnimation(fig, update_hist, n_frames, fargs=(x_velocities,))\n",
    "anim.save('./Assets/x_vel_hist.mp4', fps = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "last_vels = particles['vy{}'.format(0)]\n",
    "sns.distplot(last_vels)\n",
    "plt.xlabel('vy, timestep 0')\n",
    "plt.ylabel('density')\n",
    "plt.title('distribution of y velocity at t=0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_vels = particles['vy{}'.format(timesteps)]\n",
    "sns.distplot(last_vels)\n",
    "plt.xlabel('vy, last timestep')\n",
    "plt.ylabel('density')\n",
    "plt.title('distribution of y velocity at t=last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temperature of solvent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_2_t = [particles[['vx{}'.format(t), 'vy{}'.format(t)]]**2 for t in range(timesteps)]\n",
    "#print(v_2_t)\n",
    "avg_v_2_t = [v_2_particles.sum().sum()/len(v_2_particles) for v_2_particles in v_2_t]# first col sum, then row sum (sum vxs, then sum vys)\n",
    "print('Average sqared velocities after first timestep:\\n{}'.format(v_2_t[0].sum()/len(v_2_t[0])))\n",
    "print('Average v_x2 after last timestep:\\n{}'.format(v_2_t[timesteps-1].sum()/len(v_2_t[timesteps-1])))\n",
    "\n",
    "particle_mass = float(constants['particle_mass'])\n",
    "\n",
    "temp_t = np.array(avg_v_2_t)\n",
    "plt.plot(temp_t)\n",
    "#plot = sns.lineplot(data=temp_t)\n",
    "plt.xlabel('Timestep')\n",
    "plt.ylabel('average of v2')\n",
    "plt.title('Temperature is increasing')\n",
    "plt.savefig('Assets/temperature.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Animations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "print('Animating Quiver ...\\n')\n",
    "\n",
    "# First set up the figure, the axis, and the plot element we want to animate\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(xlim=(x_0_region, x_max_region), ylim=(y_0_region, y_max_region))\n",
    "\n",
    "quiv = ax.quiver(I, J, 10**-12*U[0], 10**-12*V[0], scale = 1) #10**-5*U10**-5*V\n",
    "\n",
    "# initialization function: plot the background of each frame\n",
    "def init():\n",
    "    #quiv.set_data([], [], [], [])\n",
    "    return quiv,\n",
    "\n",
    "# animation function.  This is called sequentially\n",
    "def animate(it, quiv, I, J):\n",
    "    #color = np.sqrt(U[it]**2 + V[it]**2)\n",
    "    quiv.set_UVC(10**-12*U[it], 10**-12*V[it]) #*10**-5*\n",
    "    if (it % 10 == 0):\n",
    "        print('--Created {} frame.\\n'.format(it))\n",
    "    #quiv.set_color(color)\n",
    "    return quiv,\n",
    "\n",
    "# call the animator.  blit=True means only re-draw the parts that have changed.\n",
    "anim = animation.FuncAnimation(fig, animate, fargs = (quiv, I, J),#init_func=init,\n",
    "                               frames=timesteps, blit=False)\n",
    "\n",
    "# save the animation as an mp4.  This requires ffmpeg or mencoder to be\n",
    "# installed.  The extra_args ensure that the x264 codec is used, so that\n",
    "# the video can be embedded in html5.  You may need to adjust this for\n",
    "# your system: for more information, see\n",
    "# http://matplotlib.sourceforge.net/api/animation_api.html\n",
    "anim.save('./Assets/quiver_animation.mp4', fps=5) #extra_args=['-vcodec', 'libx264'])\n",
    "print('Animated and saved!')\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "import seaborn as sns\n",
    "\n",
    "print('Animating Heatmap ...\\n')\n",
    "\n",
    "# First set up the figure, the axis, and the plot element we want to animate\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(xlim=(x_0_region, x_max_region), ylim=(y_0_region, y_max_region))\n",
    "sns.heatmap(pivots[0], square = True, xticklabels = False, yticklabels = False, cbar = False)#,cbar_kws={\"fraction\": 0.046, \"pad\": 0.005})\n",
    "\n",
    "# initialization function: plot the background of each frame\n",
    "def init():\n",
    "    plt.clf()\n",
    "    ax = sns.heatmap(pivots[0], square = True, xticklabels = False, yticklabels = False, cbar = False)#,cbar_kws={\"fraction\": 0.046, \"pad\": 0.005})\n",
    "    #return heatmap,\n",
    "\n",
    "# animation function.  This is called sequentially\n",
    "def animate(it):\n",
    "    plt.clf()\n",
    "    ax = sns.heatmap(pivots[it], square = True, xticklabels = False, yticklabels = False, cbar = False)#,cbar_kws={\"fraction\": 0.046, \"pad\": 0.005})\n",
    "    ax.set_xlim((x_0_region, x_max_region))\n",
    "    ax.set_ylim((y_0_region, y_max_region))\n",
    "    if (it % 10 == 0):\n",
    "        print('--Created {} frame.\\n'.format(it))\n",
    "    #return heatmap\n",
    "\n",
    "# call the animator.  blit=True means only re-draw the parts that have changed.\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=timesteps)\n",
    "\n",
    "# save the animation as an mp4.  This requires ffmpeg or mencoder to be\n",
    "# installed.  The extra_args ensure that the x264 codec is used, so that\n",
    "# the video can be embedded in html5.  You may need to adjust this for\n",
    "# your system: for more information, see\n",
    "# http://matplotlib.sourceforge.net/api/animation_api.html\n",
    "anim.save('./Assets/heatmap_animation.mp4', fps=5) #extra_args=['-vcodec', 'libx264'])\n",
    "print('Animated and saved!')\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "\n",
    "print('Animating particles ...')\n",
    "# First set up the figure, the axis, and the plot element we want to animate\n",
    "point_size = 0.1\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(xlim=(x_0_region, x_max_region), ylim=(0, y_max_region))\n",
    "scatter, = ax.plot(particles['x0'], particles['y0'], \"o\", markersize = point_size)\n",
    "\n",
    "x = 'x'\n",
    "y = 'y'\n",
    "\n",
    "# initialization function: plot the background of each frame\n",
    "def init():\n",
    "    #quiv.set_data([], [], [], [])\n",
    "    return scatter,\n",
    "\n",
    "# animation function.  This is called sequentially\n",
    "def animate(it):\n",
    "    scatter.set_xdata(particles[x + str(it)])\n",
    "    scatter.set_ydata(particles[y + str(it)])\n",
    "    if (it % 10 == 0):\n",
    "        print('--Created {} frame.\\n'.format(it))\n",
    "    return scatter,\n",
    "\n",
    "# call the animator.  blit=True means only re-draw the parts that have changed.\n",
    "anim = animation.FuncAnimation(fig, animate, #init_func=init,\n",
    "                               frames=timesteps, blit=True)\n",
    "\n",
    "# save the animation as an mp4.  This requires ffmpeg or mencoder to be\n",
    "# installed.  The extra_args ensure that the x264 codec is used, so that\n",
    "# the video can be embedded in html5.  You may need to adjust this for\n",
    "# your system: for more information, see\n",
    "# http://matplotlib.sourceforge.net/api/animation_api.html\n",
    "anim.save('./Assets/scatterplot_animation.mp4', fps=5, extra_args=['-vcodec', 'libx264'])\n",
    "print('Animated and saved!')\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "\n",
    "print('Animating Streamplot ...\\n')\n",
    "\n",
    "# First set up the figure, the axis, and the plot element we want to animate\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(xlim=(x_0_region, x_max_region), ylim=(y_0_region, y_max_region))\n",
    "color = np.sqrt(U[0]**2 + V[0]**2)\n",
    "stream = ax.streamplot(I, J, U[0], V[0], color=color, density = streamplot_density)\n",
    "\n",
    "# initialization function: plot the background of each frame\n",
    "def init():\n",
    "    #quiv.set_data([], [], [], [])\n",
    "    return stream\n",
    "\n",
    "# animation function.  This is called sequentially\n",
    "def animate(it):\n",
    "    ax.collections = [] # clear lines streamplot\n",
    "    ax.patches = [] # clear arrowheads streamplot\n",
    "    color = np.sqrt(U[it]**2 + V[it]**2)\n",
    "    stream = ax.streamplot(I, J, U[it], V[it], color=color, density = streamplot_density)\n",
    "    if (it % 10 == 0):\n",
    "        print('--Created {} frame.\\n'.format(it))\n",
    "    return stream\n",
    "\n",
    "# call the animator.  blit=True means only re-draw the parts that have changed.\n",
    "anim = animation.FuncAnimation(fig, animate, #init_func=init,\n",
    "                               frames=timesteps, blit=False)\n",
    "\n",
    "# save the animation as an mp4.  This requires ffmpeg or mencoder to be\n",
    "# installed.  The extra_args ensure that the x264 codec is used, so that\n",
    "# the video can be embedded in html5.  You may need to adjust this for\n",
    "# your system: for more information, see\n",
    "# http://matplotlib.sourceforge.net/api/animation_api.html\n",
    "anim.save('./Assets/streamplot_animation.mp4', fps=5) #extra_args=['-vcodec', 'libx264'])\n",
    "print('Animated and saved!')\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conservation of number of particles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of particles is (just for convenience) plotted and it stays constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "nums = []\n",
    "for pivot in pivots:\n",
    "    nums.append(sum(sum(lis) for lis in pivot.values))\n",
    "\n",
    "plt.plot(nums)\n",
    "plt.title('Variation in number of particles with timesteps')\n",
    "plt.ylabel('Number of Particles')\n",
    "#plt.ylim((79990, 80010))\n",
    "plt.xlabel('Timestep')\n",
    "plt.savefig('./Assets/number_particles.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Constant number of particles](Assets/number_particles.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conservation of momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the angle of rotation in the collision step is chosen randomly, and the streaming step does not change momentum, in a large system momentum should be conserved. The velocities of particles were taken and added up. The base momentum is the initial momentum, the error (or variation) from this base is plotted below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "momentum_x = []\n",
    "momentum_y = []\n",
    "for it in range(0, timesteps-1):\n",
    "    vx = sum(particles['vx{}'.format(it)])\n",
    "    vy = sum(particles['vy{}'.format(it)])\n",
    "    momentum_x.append(vx)\n",
    "    momentum_y.append(vy)\n",
    "\n",
    "base_momentum_x = momentum_x[0]\n",
    "base_momentum_y = momentum_y[0]\n",
    "error_x = [base_momentum_x - m for m in momentum_x]\n",
    "error_y = [base_momentum_y - m for m in momentum_y]\n",
    "plt.plot(error_x)\n",
    "plt.title('Variation in x-Velocity, initially: {}'.format(round(base_momentum_x, 2)))\n",
    "plt.xlabel('Timestep')\n",
    "plt.ylabel('x-Velocity')\n",
    "plt.savefig('./Assets/x_velocity_variation.png')\n",
    "plt.show()\n",
    "#plt.close()\n",
    "plt.plot(error_y)\n",
    "plt.title('Variation in y-Velocity, initally: {}'.format(round(base_momentum_y, 2)))\n",
    "plt.xlabel('Timestep')\n",
    "plt.ylabel('y-Velocity')\n",
    "plt.savefig('./Assets/y_velocity_variation.png')\n",
    "plt.show()\n",
    "#plt.close()\n",
    "plt.plot(error_x, error_y, \"o\", markersize = 3)\n",
    "plt.title('Variation in velocity')\n",
    "plt.xlabel('Variation in x-velocity')\n",
    "plt.ylabel('Variation in y-velocity')\n",
    "plt.savefig('./Assets/velocity_variation.png')\n",
    "plt.show()\n",
    "#plt.close()\n",
    "# -----------------------------------\n",
    "\n",
    "\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Variation in x-velocity throughout simulation](Assets/x_velocity_variation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Variation in y-velocity throughout simulation](Assets/y_velocity_variation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Variation in velocity throughout simulation](Assets/velocity_variation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error $\\sim 10^{-5}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collision step of the MPCD algorithm conserves energy _locally_, which is to say on a cell level. [@winkl2009] The energy should also be conserved globally, since no force is acting upon the particles _yet_, the streaming and collision steps conserve energy, and the particle number remains the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To inspect this, the energy of every particle is added up. The base energy is the initial energy, the error (or variation from this base) is calculated and plotted below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def square(lis):\n",
    "    for e in lis:\n",
    "        yield e**2\n",
    "\n",
    "xvels_squared = []\n",
    "for cell_xvels in U:\n",
    "    xvels_squared.append(sum(sum(square(lis)) for lis in cell_xvels))\n",
    "#print(xvels)\n",
    "yvels_squared = []\n",
    "for cell_yvels in V:\n",
    "    yvels_squared.append(sum(sum(square(lis)) for lis in cell_yvels))\n",
    "assert(len(xvels) == len(yvels))\n",
    "it = 0\n",
    "energy_cell_level = []\n",
    "mass = 2.988e-26\n",
    "for xvel_squared in xvels_squared:\n",
    "    yvel_squared = yvels_squared[it]\n",
    "    energy_cell_level.append((xvel_squared + yvel_squared)) # might add mass here\n",
    "    \n",
    "plt.plot(energy_cell_level)\n",
    "plt.title('Variation in energy, cell method')\n",
    "plt.xlabel('Timestep')\n",
    "plt.ylabel('Energy')\n",
    "plt.savefig('./Assets/constant_energy_cellcalc.png')\n",
    "plt.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error $\\sim 10^{-8}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to Word doc (others possible too, f.ex. .tex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just do it manually, it works on anaconda env datascience\n",
    "\n",
    "import subprocess\n",
    "#automatic document conversion to markdown and then to word\n",
    "#first convert the ipython notebook paper.ipynb to markdown\n",
    "subprocess.run(\"jupyter nbconvert --to markdown thesis.ipynb --output-dir='./Generated'\") #--output-dir='./Generated'\n",
    "#next remove code\n",
    "path = \"./Generated/thesis.md\"\n",
    "with open(path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    idx = []\n",
    "    idx_files = []\n",
    "    for i, line in enumerate(lines):\n",
    "        if (line.startswith(\"```\")):\n",
    "            idx.append(i)\n",
    "        if (\"thesis_files\" in line):\n",
    "            c = line.find(\"thesis_files\")\n",
    "            lines[i] = line[0:c] + \"\" + line[c:]\n",
    "\n",
    "idx = sorted(idx, reverse=True) # reverse order so not deleting lines and then missing others\n",
    "for current, previous in zip(idx[::2], idx[1::2]):\n",
    "    print(\"Deleting {p}:{c}\".format(p=previous, c=current+1))\n",
    "    print('\\n'.join(lines[previous:current+1]))\n",
    "    del lines[previous:current+1]\n",
    "    \n",
    "with open(path, \"w\") as f:\n",
    "    #f.write(\"\\\\newcommand{\\matr}[1]\\\\textbf{#1}\")\n",
    "    #f.write(\"\\\\newcommand{\\\\vect}[1]{\\\\vec{#1}}\")\n",
    "    for line in lines:\n",
    "        f.write(\"%s\" % line)\n",
    "#next convert markdown to ms word\n",
    "conversion_tex = \"pandoc -s ./Generated/thesis.md -o ./Generated/thesis.tex --filter pandoc-citeproc --bibliography=\\\"list.bib\\\" --csl=\\\"apa.csl\\\"\"\n",
    "subprocess.run(conversion_tex)\n",
    "conversion_pdf = \"pandoc -s ./Generated/thesis.md -o ./Generated/thesis.pdf --filter pandoc-citeproc --bibliography=\\\"list.bib\\\" --csl=\\\"apa.csl\\\"\"\n",
    "subprocess.run(conversion_pdf)\n",
    "# LATEX TO DOCX pandoc -s math.tex -o example30.docx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equation Numbering jupyter extension\n",
    "conda install -c conda-forge jupyter_contrib_nbextensions\n",
    "\n",
    "jupyter contrib nbextension install --user\n",
    "\n",
    "jupyter nbextension enable equation-numbering/main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn equation numbering on/off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "MathJax.Hub.Config({\n",
    "    TeX: { equationNumbers: { autoNumber: \"AMS\" } }\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renumber equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "MathJax.Hub.Queue(\n",
    "  [\"resetEquationNumbers\", MathJax.InputJax.TeX],\n",
    "  [\"PreProcess\", MathJax.Hub],\n",
    "  [\"Reprocess\", MathJax.Hub]\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
